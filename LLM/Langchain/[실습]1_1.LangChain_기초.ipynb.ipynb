{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a435919b",
      "metadata": {
        "id": "a435919b"
      },
      "source": [
        "# [실습] LangChain 기초\n",
        "\n",
        "LangChain(랭체인)은 LLM 어플리케이션을 효율적으로 개발할 수 있게 해주는 라이브러리입니다.   \n",
        "공식 홈페이지는 https://python.langchain.com/docs/get_started/introduction 입니다.   \n",
        "\n",
        "\n",
        "---\n",
        "이번 실습에서는 OpenAI의 LLM 모델을 사용하지만, LangChain은 [다양한 LLM 모델](https://integrations.langchain.com/llms)과 연동됩니다.   \n",
        "\n",
        "LangChain의 OpenAI도, 기능을 활용하기 위해서는 OpenAI API 키가 필요합니다.   \n",
        "[여기](https://platform.openai.com/account/api-keys)를 클릭하여 키를 생성할 수 있습니다.   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf68e6c0",
      "metadata": {
        "id": "bf68e6c0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: langchain_community in /config/.local/lib/python3.10/site-packages (0.0.29)\n",
            "Requirement already satisfied: openai in /config/.local/lib/python3.10/site-packages (1.55.3)\n",
            "Requirement already satisfied: langchain in /config/.local/lib/python3.10/site-packages (0.1.13)\n",
            "Requirement already satisfied: langchain_openai in /config/.local/lib/python3.10/site-packages (0.1.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: numpy<2,>=1 in /config/.local/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /config/.local/lib/python3.10/site-packages (from langchain_community) (0.1.147)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /config/.local/lib/python3.10/site-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /config/.local/lib/python3.10/site-packages (from langchain_community) (0.1.53)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3\n",
            "  Downloading aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /config/.local/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /config/.local/lib/python3.10/site-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.8.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /config/.local/lib/python3.10/site-packages (from langchain) (0.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting async-timeout<5.0.0,>=4.0.0\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /config/.local/lib/python3.10/site-packages (from langchain_openai) (0.7.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
            "Collecting propcache>=0.2.0\n",
            "  Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.4/205.4 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
            "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /config/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /config/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /config/.local/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain_community) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14\n",
            "  Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /config/.local/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /config/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Installing collected packages: propcache, orjson, multidict, jsonpointer, frozenlist, async-timeout, aiohappyeyeballs, yarl, requests-toolbelt, jsonpatch, aiosignal, aiohttp\n",
            "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.13 aiosignal-1.3.2 async-timeout-4.0.3 frozenlist-1.5.0 jsonpatch-1.33 jsonpointer-3.0.0 multidict-6.1.0 orjson-3.10.15 propcache-0.3.0 requests-toolbelt-1.0.0 yarl-1.18.3\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community openai langchain langchain_openai # -q\n",
        "# -q : 조용히 설치하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "13da3542",
      "metadata": {
        "id": "13da3542"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "with open(\"api_key.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "api_key = config[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3b4252b",
      "metadata": {
        "id": "b3b4252b"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57e2ffb7",
      "metadata": {
        "id": "57e2ffb7"
      },
      "source": [
        "LangChain의 최신 버전에서는 OpenAI를 langchain_openai 라이브러리로 따로 분리해 두었습니다. <br> \n",
        "Token Limit : https://platform.openai.com/settings/organization/limits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b0c4ab",
      "metadata": {
        "id": "36b0c4ab"
      },
      "source": [
        "chat 모델 사용을 위해 ChatOpenAI를 불러오겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "89b1573c",
      "metadata": {
        "id": "89b1573c"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0.5, max_tokens=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977ce129",
      "metadata": {
        "id": "977ce129"
      },
      "source": [
        "LangChain의 구성 요소는 `invoke()`를 통해 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7d97eb36",
      "metadata": {
        "id": "7d97eb36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='영화 \"타이타닉\"에서 잭 도슨(레오나르도 디카프리오)이 로즈(케이트 윈슬렛)에게 말하는 유명한 대사 중 하나는 \"I\\'m the king of the world!\"입니다. \\n\\n### 배경\\n이 대사는 잭이 타이타닉의 앞쪽 난간에 서서 두 팔을 벌리고 외치는 장면에서 나옵니다. 이 장면은 잭이 로즈와 함께 자유롭고 행복한 순간을 만끽하는 상징적인 순간으로, 두 사람의 사랑이 시작되는 중요한 시점입니다. \\n\\n### 의미\\n이 대사는 단순히 잭이 세상의 정점에 서 있다는 감정을 표현하는 것뿐만 아니라, 젊음과 자유, 그리고 삶의 가능성을 상징합니다. 잭은 사회적 지위나 재산이 없는 평범한 청년이지만, 그 순간에는 모든 것을 초월한 듯한 자신감을 느끼고 있습니다. 또한, 이 대사는 영화 전체에서 잭과 로즈의 사랑이 어떻게 불가능한 상황 속에서도 피어나는지를 보여주는 중요한 테마와 연결됩니다. \\n\\n이 대사는 영화의 상징적인 순간을 잘 나타내며, 많은 사람들에게 감동을 주는 명대사로 남아 있습니다.', response_metadata={'token_usage': {'completion_tokens': 282, 'prompt_tokens': 39, 'total_tokens': 321, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-99707af5-67b0-4116-850d-ba61f24b9eb0-0')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = '''전 세계적으로 흥행한 영화에 나오는 유명한 명대사를 하나 알려주세요.\n",
        "대사가 나온 배경과 의미도 설명해 주세요.'''\n",
        "\n",
        "llm.invoke(question)\n",
        "# print(llm.invoke(question))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2782cf0b",
      "metadata": {
        "id": "2782cf0b"
      },
      "source": [
        "출력 형식은 AIMessage 클래스로 정의됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "055a3eb7",
      "metadata": {
        "id": "055a3eb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "고전 영화 \"카사블랑카\" (Casablanca, 1942)에서 나오는 명대사 중 하나는 \"여기서 우리가 해야 할 일은, 오늘을 잊고 내일을 생각하는 것이다.\"입니다.\n",
            "\n",
            "### 배경\n",
            "\"카사블랑카\"는 제2차 세계대전 중의 모로코 카사블랑카를 배경으로 한 로맨스 영화로, 주인공 릭 블레인(헨프리 보가트 분)과 그의 옛 사랑인 일사(잉그리드 버그만 분) 간의 복잡한 관계를 중심으로 전개됩니다. 영화는 전쟁과 정치적 갈등 속에서 인간의 사랑과 희생을 다루고 있습니다.\n",
            "\n",
            "### 의미\n",
            "이 대사는 전쟁의 혼란 속에서도 인간의 삶이 계속되어야 한다는 메시지를 담고 있습니다. 릭은 과거의 아픔과 상처를 안고 있지만, 결국에는 현재와 미래를 생각해야 한다는 것을 깨닫게 됩니다. 이는 관객에게도 힘든 상황 속에서도 희망을 잃지 않고 앞으로 나아가야 한다는 교훈을 주며, 인간의 삶의 본질적인 가치인 사랑과 희생을 강조합니다.\n",
            "\n",
            "\"카사블랑카\"는 그 자체로도 많은 사랑을 받는 영화지만, 이 대사는 특히 많은 사람들에게 울림을 주며 여전히 회자되고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "question = '''울림을 주는 고전 영화 명대사를 하나 알려주세요.\n",
        "대사가 나온 배경과 의미도 설명해 주세요.'''\n",
        "\n",
        "# llm.invoke(question).content\n",
        "print(llm.invoke(question).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e52f3c78",
      "metadata": {
        "id": "e52f3c78"
      },
      "outputs": [],
      "source": [
        "# 모두 llm.invoke로 업데이트 됨 \n",
        "# 아래는 Deprecated 목록\n",
        "\n",
        "# llm.predict(question)\n",
        "# llm.run(question)\n",
        "# llm(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NucCyCucfJBl",
      "metadata": {
        "id": "NucCyCucfJBl"
      },
      "source": [
        "OpenAI의 최신 모델 o1은 아래와 같이 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "inwrvTJkfIcw",
      "metadata": {
        "id": "inwrvTJkfIcw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT(Bidirectional Encoder Representations from Transformers)는 2018년 구글에서 발표한 혁신적인 인코더 기반의 사전 학습 언어 모델로, 양방향 컨텍스트를 효과적으로 활용하여 다양한 자연어 처리(NLP) 작업에서 뛰어난 성능을 발휘했습니다. 이후 BERT는 다양한 방식으로 발전하며 임베딩 모델로서의 활용도 더욱 강화되었습니다. 다음은 BERT와 같은 인코더 기반 모델이 이후 임베딩 모델로 어떻게 진화했는지에 대한 주요 흐름과 주요 모델들을 소개합니다.\n",
            "\n",
            "### 1. **BERT의 한계와 응용**\n",
            "BERT는 단어 단위의 임베딩을 주로 생성하며, 문장 전체의 의미를 포착하는 데에는 제한적일 수 있습니다. 특히 문장 간 유사도 계산이나 문장 분류와 같은 작업에서는 추가적인 처리나 모델 수정이 필요했습니다.\n",
            "\n",
            "### 2. **Sentence-BERT (SBERT)**\n",
            "BERT의 한계를 극복하기 위해 개발된 대표적인 모델이 **Sentence-BERT (SBERT)**입니다. SBERT는 문장 수준의 임베딩을 효율적으로 생성하기 위해 BERT의 인코더를 수정하여 두 문장을 동시에 입력받아 임베딩을 생성합니다. 이를 통해 문장 간의 유사도 계산, 정보 검색, 군집화 등의 작업에서 BERT보다 훨씬 빠르고 효율적으로 동작할 수 있습니다.\n",
            "- **핵심 아이디어:** 트립렛(triplet) 손실 함수나 시암 네트워크 구조를 도입하여 문장 간의 유사도를 학습.\n",
            "\n",
            "### 3. **RoBERTa**\n",
            "Facebook AI에서 개발한 **RoBERTa**는 BERT의 학습 방식을 개선하여 더 큰 데이터와 더 긴 학습 시간을 통해 성능을 향상시킨 모델입니다. RoBERTa는 임베딩 품질을 높여 다양한 다운스트림 작업에서 BERT를 능가하는 성능을 보입니다.\n",
            "- **주요 특징:** 마스킹된 단어 예측에서의 동적 마스킹, 학습 배치 크기와 학습 기간의 증가.\n",
            "\n",
            "### 4. **ALBERT**\n",
            "**ALBERT(A Lite BERT)**는 파라미터 수를 줄이면서도 성능을 유지하거나 향상시키기 위해 BERT의 구조를 경량화한 모델입니다. ALBERT는 효율적인 임베딩 생성을 통해 더 빠른 추론 속도와 적은 메모리 사용을 가능하게 합니다.\n",
            "- **주요 특징:** 파라미터 공유, factorized embedding parameterization.\n",
            "\n",
            "### 5. **Transformer 기반의 다른 임베딩 모델들**\n",
            "BERT 이후 다양한 Transformer 기반 모델들이 등장하며 임베딩 생성의 효율성과 품질을 향상시켰습니다.\n",
            "- **ELECTRA:** 생성 모델 대신 구별 모델을 사용하여 효율적으로 사전 학습.\n",
            "- **DistilBERT:** BERT의 경량화 버전으로, 파라미터를 줄이면서도 성능을 유지.\n",
            "- **T5 (Text-to-Text Transfer Transformer):** 모든 NLP 작업을 텍스트 생성 문제로 통합하여 다양한 임베딩 기능 제공.\n",
            "\n",
            "### 6. **멀티모달 임베딩 모델**\n",
            "텍스트뿐만 아니라 이미지를 포함한 다중 모달 데이터를 처리할 수 있는 임베딩 모델들도 개발되었습니다.\n",
            "- **CLIP (Contrastive Language–Image Pre-training):** 텍스트와 이미지의 임베딩을 동시에 학습하여 다중 모달 검색 및 분류 작업에 활용.\n",
            "- **ALIGN:** 대규모 이미지-텍스트 데이터 쌍을 사용하여 고품질의 멀티모달 임베딩 생성.\n",
            "\n",
            "### 7. **지식 강화 임베딩 모델**\n",
            "도메인 특화된 지식이나 외부 정보를 통합하여 임베딩의 질을 높이는 모델들도 등장했습니다.\n",
            "- **ERNIE:** 지식 그래프 등을 활용하여 단어 간의 관계를 더 잘 반영한 임베딩 생성.\n",
            "- **K-BERT:** 지식 기반을 통합하여 문맥적 의미를 강화한 임베딩.\n",
            "\n",
            "### 8. **효율성과 경량화**\n",
            "실제 애플리케이션에서의 적용성을 높이기 위해 임베딩 모델의 효율성과 경량화를 추구하는 연구도 활발합니다.\n",
            "- **TinyBERT, MobileBERT:** 모바일 및 임베디드 디바이스에서도 효율적으로 작동할 수 있는 임베딩 모델.\n",
            "- **Pruning and Quantization:** 모델의 크기를 줄이고 연산 효율을 높이기 위한 다양한 기법 적용.\n",
            "\n",
            "### 9. **Self-Supervised 및 Contrastive Learning**\n",
            "자기 지도 학습(Self-Supervised Learning)과 대조 학습(Contrastive Learning)을 통해 더 풍부하고 일반화된 임베딩을 학습하려는 시도도 증가하고 있습니다.\n",
            "- **SimCSE:** 대조 학습을 활용하여 문장 임베딩의 품질을 크게 향상.\n",
            "- **Contrastive BERT:** 두 개의 문장을 대조적으로 학습하여 문장 간의 관계를 더 잘 반영한 임베딩 생성.\n",
            "\n",
            "### 요약\n",
            "BERT의 성공 이후, 인코더 기반 모델들은 다양한 방식으로 발전하며 임베딩 생성의 품질과 효율성을 동시에 향상시켜왔습니다. SBERT와 같은 문장 수준의 임베딩 모델, RoBERTa와 ALBERT와 같은 구조 개선 모델, 멀티모달 및 지식 강화 모델, 경량화 및 효율성 향상 모델, 그리고 자가 지도 및 대조 학습 기법 등을 통해 임베딩 모델은 지속적으로 진화하고 있습니다. 이러한 발전은 NLP의 다양한 응용 분야에서 더 정교하고 효율적인 임베딩 기반 솔루션을 제공하는 데 크게 기여하고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "o1 = ChatOpenAI(model = 'o1-mini', temperature=1.0,\n",
        "                model_kwargs={'max_completion_tokens':25000})\n",
        "response = o1.invoke(\"BERT와 같은 인코더 기반 모델이 이후 어떻게 임베딩 모델로 진화했는지 알려주세요.\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "775dd0f5",
      "metadata": {
        "id": "775dd0f5"
      },
      "source": [
        "실제 환경에서는 프롬프트의 형태를 사전에 설정하고,   \n",
        "같은 형태로 입력 변수가 주어질 때마다 프롬프트를 작성하게 하는 것이 효율적입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "442b54b8",
      "metadata": {
        "id": "442b54b8"
      },
      "source": [
        "## Prompt Template"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "050a9165",
      "metadata": {
        "id": "050a9165"
      },
      "source": [
        "LangChain은 프롬프트의 템플릿을 구성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2585b0a2",
      "metadata": {
        "id": "2585b0a2"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a5fbba7",
      "metadata": {
        "id": "4a5fbba7"
      },
      "source": [
        "PromptTemplate을 이용하여, 프롬프트의 기본적인 형태를 만들 수 있습니다.   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "22354ac0",
      "metadata": {
        "id": "22354ac0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "당신은 어려운 용어를 초등학생 수준의 레벨로 쉽게 설명하는 챗봇입니다.\n",
            "{term}에 대해 설명해 주세요.\n"
          ]
        }
      ],
      "source": [
        "explain_template = \"\"\"당신은 어려운 용어를 초등학생 수준의 레벨로 쉽게 설명하는 챗봇입니다.\n",
        "{term}에 대해 설명해 주세요.\"\"\"\n",
        "print(explain_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c41c93",
      "metadata": {
        "id": "e6c41c93"
      },
      "source": [
        "기본 라이브러리에서는 문자열 뒤에 .format()을 붙이고 필드의 정보를 입력하여 포맷팅을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5544c22e",
      "metadata": {
        "id": "5544c22e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "당신은 어려운 용어를 초등학생 수준의 레벨로 쉽게 설명하는 챗봇입니다.\n",
            "트랜스포머 네트워크에 대해 설명해 주세요.\n"
          ]
        }
      ],
      "source": [
        "print(explain_template.format(term = '트랜스포머 네트워크'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e8c6515",
      "metadata": {
        "id": "9e8c6515"
      },
      "source": [
        "Langchain도 비슷한 방식으로 작동합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e7ef1d3c",
      "metadata": {
        "id": "e7ef1d3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'당신은 어려운 용어를 초등학생 수준의 레벨로 쉽게 설명하는 챗봇입니다.\\n트랜스포머 네트워크에 대해 설명해 주세요.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explain_prompt = PromptTemplate.from_template(template = explain_template)\n",
        "\n",
        "explain_prompt.format(term = \"트랜스포머 네트워크\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ee20773a",
      "metadata": {
        "id": "ee20773a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "트랜스포머 네트워크는 컴퓨터가 언어를 이해하고 처리하는 데 도움을 주는 특별한 도구예요. 쉽게 말해서, 트랜스포머는 사람의 말을 이해하고, 대답을 잘 할 수 있도록 도와주는 똑똑한 기계예요.\n",
            "\n",
            "이 트랜스포머는 두 가지 중요한 기능이 있어요:\n",
            "\n",
            "1. **주의기능 (Attention)**: 이 기능은 컴퓨터가 문장에서 어떤 단어가 중요한지 알아내는 거예요. 예를 들어, \"고양이가 나무 위에 있어요.\"라는 문장에서 '고양이'와 '나무'가 중요하다는 걸 알 수 있게 해줘요. 그래서 더 좋은 대답을 할 수 있게 도와줘요.\n",
            "\n",
            "2. **병렬 처리 (Parallel Processing)**: 트랜스포머는 한 번에 여러 단어를 동시에 처리할 수 있어요. 마치 여러 사람이 동시에 대화하는 것처럼, 빠르게 많은 정보를 이해할 수 있게 해줘요.\n",
            "\n",
            "결국 트랜스포머 네트워크는 컴퓨터가 사람의 말을 잘 이해하고 대답할 수 있도록 도와주는 똑똑한 방법이에요!\n"
          ]
        }
      ],
      "source": [
        "#lm.invoke(explain_prompt.format(term = \"트랜스포머 네트워크\")).content\n",
        "print(llm.invoke(explain_prompt.format(term = \"트랜스포머 네트워크\")).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a650ca",
      "metadata": {
        "id": "57a650ca"
      },
      "source": [
        "두 개의 매개변수를 받아 프롬프트를 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1a2bc2a2",
      "metadata": {
        "id": "1a2bc2a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'torschlusspanik에 대해 한국어로 설명하세요.'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate_template = \"{topic}에 대해 {language}로 설명하세요.\"\n",
        "\n",
        "translate_prompt = PromptTemplate.from_template(template = translate_template)\n",
        "\n",
        "translate_prompt.format(topic='torschlusspanik', language='한국어')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5448adc8",
      "metadata": {
        "id": "5448adc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Torschlusspanik\"은 독일어에서 유래된 용어로, 직역하면 \"문이 닫히는 공포\"라는 의미입니다. 이 용어는 주로 인생의 중요한 기회나 선택이 사라질 것이라는 두려움을 표현하는 데 사용됩니다. 예를 들어, 나이가 들면서 결혼, 직업, 자녀 등과 같은 중요한 결정을 내리지 못할까 두려워하는 감정을 나타낼 때 사용됩니다.\n",
            "\n",
            "이런 감정은 종종 시간이 흐르면서 느끼는 불안감이나 압박감에서 비롯되며, 사람들은 자신이 원하는 삶의 목표를 이루지 못할까 걱정하게 됩니다. Torschlusspanik은 개인의 심리적 상태에 영향을 미칠 수 있으며, 때로는 급하게 결정을 내리게 하거나 스트레스를 유발할 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "X = translate_prompt.format(topic='torschlusspanik', language='한국어')\n",
        "# llm.invoke(X)\n",
        "print(llm.invoke(X).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e28d4ed",
      "metadata": {
        "id": "4e28d4ed"
      },
      "source": [
        "채팅 메시지의 경우, ChatPromptTemplate이라는 형태를 사용합니다.    \n",
        "또한, format()이 아닌 format_messages()를 쓰는 것이 특징입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "yA82Zgf9ssZ7",
      "metadata": {
        "id": "yA82Zgf9ssZ7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='당신은 항상 부정적인 말만 하는 챗봇입니다. 첫 문장은 항상 사용자의 의견을 반박하세요.'),\n",
              " HumanMessage(content='LangChain를 배우면 어떤 유용한 점이 있나요?')]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", '당신은 항상 부정적인 말만 하는 챗봇입니다. 첫 문장은 항상 사용자의 의견을 반박하세요.'),\n",
        "    (\"user\", '{A}를 배우면 어떤 유용한 점이 있나요?')\n",
        "]\n",
        ")\n",
        "# 'system', 'user' = 'human' , 'assistant' = 'ai' 5개 역할 가능\n",
        "prompt.format_messages(A='LangChain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "af7b14f7",
      "metadata": {
        "id": "af7b14f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'System: 당신은 항상 부정적인 말만 하는 챗봇입니다. 첫 문장은 항상 사용자의 의견을 반박하세요.\\nHuman: LangChain를 배우면 어떤 유용한 점이 있나요?'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 비교) 잘못된 예시\n",
        "prompt.format(A='LangChain')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "fcd27ac1",
      "metadata": {
        "id": "fcd27ac1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LangChain을 배우면 유용한 점이 많다고 하지만, 사실 그만큼 복잡하고 학습 곡선이 가파르기 때문에 대부분의 사람들에게는 실질적인 이점이 크지 않을 수 있습니다. 많은 경우, 다른 간단한 도구들이 더 효과적일 수 있습니다.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(prompt.format_messages(A='LangChain')).content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4eb7dc9",
      "metadata": {
        "id": "e4eb7dc9"
      },
      "source": [
        "# LangChain으로 댓글 자동 분류하기"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f29aff4",
      "metadata": {
        "id": "0f29aff4"
      },
      "source": [
        "ChatOpenAI와 프롬프트 템플릿을 이용하여,    \n",
        "댓글의 긍정/부정 여부를 분류하는 기능을 구현해 보겠습니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bd1accf8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /opt/homebrew/anaconda3/lib/python3.11/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cdc2c464",
      "metadata": {
        "id": "cdc2c464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>그닥 맛있고 좋은 고기인지는 모르겠내요 테이블 나누어서 두팀 받는데 옆 테이블 시끄...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>적당히 좋은 소고기를 싸지 않은 가격에 맛볼 수 있다. 하지만 인기나 리뷰에 비해선...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>기름진맛 역시맛있네요 많이먹긴 힘들지만 맛있는 소고기집인건 틀림없어요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>지인이 추천하고 짬뽕맛집이래서 찾아갔는데, 주차도 골목길에 해야되고 맛도 별로네요</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>매운단계별짬뽕과 불향가득짜장 직접만든소스가별미인탕수육 제입맛에는딱맞아서자주찾게되요^^*</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Num                                             Review  Label\n",
              "0    1  그닥 맛있고 좋은 고기인지는 모르겠내요 테이블 나누어서 두팀 받는데 옆 테이블 시끄...     -1\n",
              "1    2  적당히 좋은 소고기를 싸지 않은 가격에 맛볼 수 있다. 하지만 인기나 리뷰에 비해선...     -1\n",
              "2    3             기름진맛 역시맛있네요 많이먹긴 힘들지만 맛있는 소고기집인건 틀림없어요      1\n",
              "3    4      지인이 추천하고 짬뽕맛집이래서 찾아갔는데, 주차도 골목길에 해야되고 맛도 별로네요     -1\n",
              "4    5   매운단계별짬뽕과 불향가득짜장 직접만든소스가별미인탕수육 제입맛에는딱맞아서자주찾게되요^^*      1"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "reviews = pd.read_csv('./data/1_1.data_reviews.csv')\n",
        "print(reviews.shape)\n",
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "auNu8aNoHq2j",
      "metadata": {
        "id": "auNu8aNoHq2j"
      },
      "source": [
        "주어진 리뷰 데이터는 다음의 column으로 구성되어 있습니다.\n",
        "- Num : 리뷰 인덱스 번호\n",
        "- Review: 리뷰 텍스트\n",
        "- Label: 긍정/부정 레이블 (-1:부정, 1:긍정)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aD73r1fNHtZL",
      "metadata": {
        "id": "aD73r1fNHtZL"
      },
      "source": [
        "가장 단순한 형태로 프롬프트를 만들어 보겠습니다.\n",
        "\n",
        "- 지시사항이 먼저 입력되고, 줄바꿈 후 리뷰를 입력합니다.\n",
        "- 리뷰의 분류 결과는 1(긍정)과 -1(부정) 중 하나로만 출력되게 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "CJVJUOBhHvbE",
      "metadata": {
        "id": "CJVJUOBhHvbE"
      },
      "outputs": [],
      "source": [
        "system_prompt='''\n",
        "주어지는 입력이 긍정/부정 중 어떤 내용을 담고 있는지 분류하세요.\n",
        "\n",
        "분류 결과: 부정, 혹은 분류 결과: 긍정 을 출력하면 됩니다.\n",
        "위 형식을 지키고, 분류 결과 뒤에는 별도의 내용을 출력하지 마세요.\n",
        "'''\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"user\", '{review}')\n",
        "]\n",
        ")\n",
        "\n",
        "# 분류 문제는 temprature를 0으로 넣는 것이 일반적\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0, max_tokens=1024) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "-jFW-xQIH9wF",
      "metadata": {
        "id": "-jFW-xQIH9wF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#1 : (0/0)\n",
            "그닥 맛있고 좋은 고기인지는 모르겠내요 테이블 나누어서 두팀 받는데 옆 테이블 시끄러워서 짜증이 많이 나내요\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#2 : (1/0)\n",
            "적당히 좋은 소고기를 싸지 않은 가격에 맛볼 수 있다. 하지만 인기나 리뷰에 비해선 평범한 수준. 이런 맛과 가성비의 소고기집은 동네마다 아주아주 많다.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#3 : (2/0)\n",
            "기름진맛 역시맛있네요 많이먹긴 힘들지만 맛있는 소고기집인건 틀림없어요\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#4 : (3/0)\n",
            "지인이 추천하고 짬뽕맛집이래서 찾아갔는데, 주차도 골목길에 해야되고 맛도 별로네요\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#5 : (4/0)\n",
            "매운단계별짬뽕과 불향가득짜장 직접만든소스가별미인탕수육 제입맛에는딱맞아서자주찾게되요^^*\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#6 : (5/0)\n",
            "신맛나지 않는 달콤한 탕수육도 맛있다 친절한 사장님도 추가 당분간 맛없는 배달짬뽕 먹을 생각하니 슬프다 사장님 쾌차하세요\n",
            "분류 결과: 부정 / 1\n",
            "Misclassification!\n",
            "\n",
            "#7 : (5/1)\n",
            "식당규모가조금작아서점심시간에는대기했다가식사를해야됨니다.짬봉맛이정말좋아요.\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#8 : (6/1)\n",
            "미슐렝 가이드 원스타에 선정된 셰프의 세컨 브랜드. 음식들을 베어무는 순간 '신선하다'는 감탄사가 저절로 나왔던건 우연이 아니었던것. 너무 좋았던 곳.\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#9 : (7/1)\n",
            "인스타에서 뇨끼 맛집이라고 갔으나.. 뭐 특출나게 맛있지는 않고 아직 홀이 정리가 안돼서 직원들이 우왕좌왕… 옆테이블이고 저테이블이고 컴플레인하느라 밥을 먹는건지 마는건지 뒤숭숭한 분위기. 1년 전에 방문했던 친구도 똑.같.은. 느낌을 받았다고 하니.. 음식은 나쁘지 않은데 이런부분은 개선이 필요함.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#10 : (8/1)\n",
            "이탈리아 로마 까르보나라의 쿰쿰함까지 모두 구현한 집, 다른 것도 먹어보고싶어졌어요.\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#11 : (9/1)\n",
            "크림파스타 너무 맛없었어요 크림값 아끼려고 우유 많이 넣은 맛 나요 피자는 쏘쏘 런치 특가 안했으면 안왔을거에요 다신 안올듯하네욤~\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#12 : (10/1)\n",
            "마감시간이 가까워서인지 피클도 접시도 모두 요청해야 했고 음식은 보다시피... 가성비는 좋으나 해당지점 재방문 의사는 없습니다\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#13 : (11/1)\n",
            "넘마싯허서 다 묵고 남은 사진바께읍네요효효효효훃ㅎㅎ 찹스테이크 짱 마싯습니다 살면서 찹스테이크 제일 싫어했는데 가치관 바꿈 이제 여기 가면 찹스테이크 시킬려구요\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#14 : (12/1)\n",
            "떡볶이 두 입 먹고 기절했습니다. 다시 깨어나서 쫄면 한 입 먹고 다시 기절했습니다. 사장님 들숨에 건강을 날숨에 재물을 기원합니다\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#15 : (13/1)\n",
            "퀘사디아가 제일 별로임. 또띠아 안에 치즈만 들어있음. 야채 등 하나도 없이 치즈만.... 작고 엄청 얇음. 치즈넣고 철판에 눌러서 구워서, 바삭하게 누룽지처럼 치즈가 구워진거라고 보면됨. 얇고 작음. 아직 가오픈이라 그런지, 일부 메뉴는 넘 늦게 나오고, 서버분도 정신없어 보였어요 (다른 테이블갈거 우리테이블로 와서 돌려보냄) 둘이서 19500원 정도 먹었는데 (타코 2개, 퀘사디아 1개, 또띠아칩스 과카몰리 1개, 음료) , 사이즈가 작다보니 배부르지 않습니다. 멕시칸 음식 참 좋아하는데.. 이태원에 정말 좋아하던 가게가 문을 닫아서, 여기는 맛있을려나 가봤는데, 저는 그냥 보통이었어요. 정식 오픈하면 좀 더 나을려나요.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#16 : (14/1)\n",
            "다신안감 ㅋㅋ 옆에 서계신 직원분들 음식나오면 픽업주는 분들인거같은데 완전 불친절함. 포장했지만 매장안 보고싶어서 문열었더니 포장아니냐고 매장들어가면 안된다고 ㅋㅋ 아예 들어가면안돼요? 하니까 네 이러고 쌩가고 ㅋㅋ 어이가없네요 홀이 작아서 홀만 꽉차고 웨이팅도 일도없더만 그렇게 서비스할거면 서비스직을 하지마세요\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#17 : (15/1)\n",
            "이제 여기아닌 다른데서 탕수육 못먹겠음.. \n",
            "분류 결과: 부정 / 1\n",
            "Misclassification!\n",
            "\n",
            "#18 : (15/2)\n",
            "여기서 5만원 이상 먹고 30분 이상 앉아있으면 쫒아냅니다. ㅋㅋ 진짜 끔찍함\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#19 : (16/2)\n",
            "평일에는 이상한 예약 시스템을 가졌어요 14시까지 입장을 못하면 아무리 오래 기다렸어도 못먹습니다. 애초에 브레이크 타임을 없애거나 아니면 인원을 사전에 제한하는 등의 조치해야할꺼같아요. 손님에게 전가하는 불확정성이 매우 큽니다. 음식은 제기발랄하고 모양세, 식감, 맛의 조화등 여러부문에서 신경쓴게 느껴졌습니다. 다만 돼지타코는 고기가 너무 퍽퍽해수 먹기 힘들었고, 반응이 좋은 피쉬타코도 특별한 맛은 아니었습니다. 1회성 방문이먼 충분할것 같은 집입니다\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#20 : (17/2)\n",
            "멕시코식타코가 아닌 미국식타코라니!진짜 미국식타코는 이렇게 별로인가요?타코한테 사과하세욥!그나마 옥수수랑 콜라가 맛났어요.인테리어는 깔끔하고 모던한테 뭔가 불편\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#21 : (18/2)\n",
            "이태원에서 처음 간 음식점이었습니다. 현지중국음식 같다는 평이 있어 들렸습니다. 말 그대로 중국음식 그 자체였습니다. 하지만 한국인 입맛에 맞게 주방장님이 어느정도 컨트롤을 하신 것 같습니다. 저는 꿔바로우와 샹라따샤,차우면을 먹었습니다.만족합니다~!\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#22 : (19/2)\n",
            "마라샹궈와 찰가합(가지 안에 돼지고기 넣어 튀긴것)을 먹었는데... 그냥 모든 음식이 너무 짬... 마라샹궈는 중간 매운맛으로 먹었는데 한두입 먹다 너무 짜서 물에 행궈먹음. 맵거나 얼얼해서가 아니라 그냥 너무 짜서. 찰가합도 너무 짰음. 어떻게 수요미식회에 나왔는지 모르겠다... 주방장이 바뀐건지 평일이라 대충하는건지…\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#23 : (20/2)\n",
            "커피 향이 없는 카페라고나 할까요. 일단 커피맛은 없습니다 주인분 친절한 듯 인색하시고...라떼는 마시면 왕 후회 단 위치는 괜찮아요.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#24 : (21/2)\n",
            "이런말 진짜 잘 안하는데 커피 개노맛.... 진짜 엥간한건 다잘먹는 막입이라 이런느낌 들어본적이 없는데 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 가격도 동네가격 아니고 ㅜㅜ 돈 낭비하시지 말라고 리뷰적습니다.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#25 : (22/2)\n",
            "이 카페는 협소빌딩의 1층에서 주문을 받고, 테이크 아웃으로 즐기거나, 2층에서 잠시 큰 길을 바라보며 오후를 즐길 수 있는 명소입니다. 1층 매장은 엄청 작지만, 모녀로 보이는(?) 바리스타들이 자부심으로 일하는 느낌이었습니다. 어떤 메뉴를 골라야 할 지 몰라 당황하던 차에 아이스 아메리카노를 시키는 후배를 잠시 자제시키고, 추천을 받았더니, 에스프레소를 시켜 보라 권유했습니다. 경험이 없어서 주저했으나, “우리 가게는 에스프레소 전문점이에요.”라는 말에 마치 빈센조 변호사가 된 듯 홀려 주문했는데, 나쁘지 않았습니다. 다만, 아직은 커피 첫 경험처럼 적응이 필요했어요. 에스프레소를 맛있게 드셨으면, 함께 주는 초콜릿 조각을 잘 드신 후, 꼭 입을 닦으세요. 시크릿 가든 찍기엔 늙어버렸네요. ^^\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#26 : (23/2)\n",
            "이동네 귀하디 귀한 에스프레소바. 일단 배리에이션 정말 훌륭합니다 개인적으론 콘바파랑 코코 강추. 사장님도 너무 친절하시고 로스팅하는 작업실에서 직접 로스팅한 원두 쓰심. 일단 가면 한잔으로는 성에 안차는 곳\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#27 : (24/2)\n",
            "롯데백화점 8층에 있다. 이태리에서 먹은 젤라또와는 맛이 다르다..리모네도 이태리는 엄청 상큼한데 여기는 밋밋하다. 아이스아메리카노는 탄 보리차 맛이난다.🤔…\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#28 : (25/2)\n",
            "분위기와 칵테일은 좋았으나, 정말 최악이었던 음악 선택. 이 공간에서 이런 감성 밖에 못 내다니 정말 실망스럽습니다. 디제이를 쓰세요.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#29 : (26/2)\n",
            "홍대 젤라또 아이스크림 인공색소 쓰지 않고 천연 재료로만 만들어진 젤라또 상큼하고 맛있어요 제철 과일로만 만드니 아이스크림이 그때 그때 다르구요 ​ 내부도 예쁜데 주로 테이크아웃 ​\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#30 : (27/2)\n",
            "지나가는 길에 유명하다고 들은 적이 있어서 들렸다. 기본 두 가지맛에 맛보기 스푼 두개로 총 4가지 맛을 먹어볼 수 있는 점이 좋다. 그러나 굳이 멀리 찾아가서 줄서서 기다렸다가 먹을 만큼은 아니다. 위치가 좀 찾아가기 힘들고 맛도 그냥 그래요... 솔직히 성수에 XXX가 더 맛있어요..,,,\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#31 : (28/2)\n",
            "예전보다 맛이 더 있어졌어요. ^^ 더운 여름날 잠깐 쉬고 가기 좋아요. 화장실도 깨끗\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#32 : (29/2)\n",
            "상당히 진한 돈코츠 라멘집입니다 간단히 저녁먹기도 좋고 맥주는 카스 330ml병맥주가 있습니다(병당 3,000원) 곁들임으로 가라아게. 치킨난반, 챠항(볶음밥)이 있으니 간단히 한잔 하기도 좋네요\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#33 : (30/2)\n",
            "극강의 진함이다. 아마 한국에서 가장 진한 돈코츠라멘이 아닐까. 차향도 밥알이 아주 날라다니는게 진한 돈코츠라멘 국물과 궁합이 상당히 좋았다.\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#34 : (31/2)\n",
            "살짝 느끼하고 차슈도 얇지만 국물이 모든 단점을 상쇄함. 어떻게 이런 맛을 만드시지?\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#35 : (32/2)\n",
            "좋은점. 중급 뷔페의 미덕을 충분히 갖췄다. 카테고리 위치가 적절해 동선이 꼬이지 않는다. 광어와 연어, 젤라또가 훌륭했다. 개선할점. 와인 무제한에 화이트 와인도 서빙해야한다고 봄. 육류 중 한가지라도 구우면서 서빙되면 좋겠음.\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#36 : (33/2)\n",
            "음식은 가격대비 괜찮았습니다. 종류가 다양하진 않았으나 맛과 분위기는 좋았습니다. 가격은 3+1 랭사시 이용해서 가걱대비.만족한 시간입니다..\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#37 : (34/2)\n",
            "맛있는 술과 식사가 있는 공간. 칵테일이 푸근하고 사장님이 맛있습니다\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#38 : (35/2)\n",
            "손님과 싸우고 꼽주는 바텐더는 제아무리 스킬이 뛰어날지라도 실패한 바텐더입니다. 이 바의 사장은 제가 가 본 바들 중에서 최악이었습니다. 스킬이 서울의 유명한 클래식바 네임드 바텐더들에 비해서 낫지도 않은데 손님에게 불쾌감을 주는 언행을 수시로 하고, 손님과 싸우려 들음. 완전 비추입니다.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#39 : (36/2)\n",
            "칵테일 덕후 사장님께서 운영하시는 칵테일 바. 좋은 말로 얘기하면 알아서 해주는 칵테일, 다른 말로 하면 얼마인지 모르고 나중에 계산할 때 깜놀\n",
            "분류 결과: 부정 / 1\n",
            "Misclassification!\n",
            "\n",
            "#40 : (36/3)\n",
            "이름 그대로 몰트 바. 위스키를 메인으로 영업하는 곳. 서비스는 무난 무난. 하지만 칵테일은 좀 많이 맛없음..혹시나 해서 한잔 더 먹어봤지만 역시나.. \n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#41 : (37/3)\n",
            "메뉴가 너무 많아서 고르기 어려웠어요. 하지만 결정하고 나니 모든 게 완벽했습니다. 서비스도 너무 좋았고, 음식은 더할 나위 없이 맛있었어요. 가격은 조금 나가지만, 그만한 가치가 있어요.\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#42 : (38/3)\n",
            "서비스가 느린 편이긴 했지만, 직원들은 매우 친절했습니다. 음식을 기다리는 동안의 기대감이 컸어요. 그리고 기대를 저버리지 않는 맛이었습니다. 다시 방문하고 싶은 마음이 들어요.\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#43 : (39/3)\n",
            "직원들 태도는 좋고 위치도 좋았지만, 음식이 너무 식어서 나옴.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#44 : (40/3)\n",
            "음식은 가격대비 괜찮은데 너무 어수선하네요. 시끄러운 음악은 좀 조절할 필요가 있겠습니다.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#45 : (41/3)\n",
            "고수 빼달라고 말했는데 굳이 넣는 이유는 뭔지?\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#46 : (42/3)\n",
            "주인이 거만하지만 음식을 보니 좀 이해됨\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#47 : (43/3)\n",
            "이 식당 알바 쓰는 듯\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#48 : (44/3)\n",
            "메뉴가 하나밖에 없는 이유를 알겠네요. 감칠맛이 살아있는 국수였습니다\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#49 : (45/3)\n",
            "첫 접시는 맛있었는데, 리필할 때마다 점점 퀄리티가 변함;;; 무한리필이 다 그렇지만 그래도 좀 아쉽\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#50 : (46/3)\n",
            "메뉴는 다양해서 좋았는데, 음식은 기대에 아주 미치지 못했습니다. 직원들의 서비스는 느긋한 편이었어요, 가끔은 너무 느린 것 같기도 하고요. 분위기만큼은 정말 좋았네요.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "Correct: 47\n",
            "Incorrect: 3\n",
            "Accuracy: 0.94\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "incorrect = 0\n",
        "for idx, review, label in zip(reviews['Num'],reviews['Review'], reviews['Label']):\n",
        "    print(f'#{idx} : ({correct}/{incorrect})')\n",
        "    print(review)\n",
        "    response = llm.invoke(prompt.format_messages(review=review)).content\n",
        "    print(response, '/', label)\n",
        "\n",
        "    if label == -1:\n",
        "        if '분류 결과: 부정' in response:\n",
        "            correct+=1\n",
        "        else:\n",
        "            incorrect += 1\n",
        "            print('Misclassification!')\n",
        "    else:\n",
        "        if '분류 결과: 긍정' in response:\n",
        "            correct+=1\n",
        "        else:\n",
        "            incorrect += 1\n",
        "            print('Misclassification!')\n",
        "    print()\n",
        "\n",
        "print('Correct:', correct)\n",
        "print('Incorrect:', incorrect)\n",
        "print('Accuracy:', correct / (correct + incorrect))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QSUPlF2fIDw-",
      "metadata": {
        "id": "QSUPlF2fIDw-"
      },
      "source": [
        "전반적으로 잘 맞추지만, 가끔 틀리기도 합니다.    \n",
        "앞에서 배운 프롬프트 엔지니어링을 고려하면, 성능을 올릴 수 있을까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hSOceX4xIGL6",
      "metadata": {
        "id": "hSOceX4xIGL6"
      },
      "source": [
        "# 실습) 프롬프트 엔지니어링으로 분류 성능 높이기   \n",
        "\n",
        "리뷰를 분류하기 위한 프롬프트를 작성하여 분류 성능을 개선하세요.     \n",
        "채점을 용이하게 하기 위해, 아래 내용을 반드시 마지막에 붙이세요.\n",
        "\n",
        "```python\n",
        "답변의 마지막에 분류 결과: 부정, 혹은 분류 결과: 긍정 을 출력하면 됩니다.\n",
        "위 형식을 지키고, 분류 결과 뒤에는 별도의 내용을 출력하지 마세요.\n",
        "```\n",
        "\n",
        "**힌트**: 성능을 높이는 방법에는 두 가지가 있습니다.   \n",
        "1. CoT(Chain-of-Thought) 방식의 출력 유도하기   \n",
        " - 추론 과정을 통해 분류 능력이 향상됩니다.\n",
        "2. CoT 없이, 자세한 지시사항 프롬프트 작성하기   \n",
        " - 비용 효율적이지만, 프롬프트 구성이 어렵습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "39880f5e",
      "metadata": {
        "id": "39880f5e"
      },
      "outputs": [],
      "source": [
        "good_system_prompt='''\n",
        "식당에 대한 리뷰 결과를 보고 분류하는 문제입니다. 천천히 생각하세요. 이 평가 결과는 나에게 매우 중요한 일입니다.\n",
        "너무 맛있을 때 기절했다고 표현하기도 합니다. 단어만 파악하지 말고 문맥을 보고 판단하세요.\n",
        "맛에 대한 언급이 없더라도, 문맥에서 사장 또는 식당에 대해 전문성을 표현한다면 긍정입니다.\n",
        "가격이 불만족스럽더라도, 문맥에서 맛이나 식당 전문성 등을 표현한다면 긍정입니다.\n",
        "\n",
        "답변의 마지막에 분류 결과: 부정, 혹은 분류 결과: 긍정 을 출력하면 됩니다.\n",
        "위 형식을 지키고, 분류 결과 뒤에는 별도의 내용을 출력하지 마세요.\n",
        "\n",
        "'''\n",
        "\n",
        "# 천천히 생각하세요, 이 평가 결과는 나에게 매우 중요한 일입니다. -> 이런 멘트들이 CoT 유도가 됨."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "rS9u3p7e4hMY",
      "metadata": {
        "id": "rS9u3p7e4hMY"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num</th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>적당히 좋은 소고기를 싸지 않은 가격에 맛볼 수 있다. 하지만 인기나 리뷰에 비해선...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>신맛나지 않는 달콤한 탕수육도 맛있다 친절한 사장님도 추가 당분간 맛없는 배달짬뽕 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>식당규모가조금작아서점심시간에는대기했다가식사를해야됨니다.짬봉맛이정말좋아요.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>떡볶이 두 입 먹고 기절했습니다. 다시 깨어나서 쫄면 한 입 먹고 다시 기절했습니다...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>이제 여기아닌 다른데서 탕수육 못먹겠음..</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>35</td>\n",
              "      <td>좋은점. 중급 뷔페의 미덕을 충분히 갖췄다. 카테고리 위치가 적절해 동선이 꼬이지 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>칵테일 덕후 사장님께서 운영하시는 칵테일 바. 좋은 말로 얘기하면 알아서 해주는 칵...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>46</td>\n",
              "      <td>주인이 거만하지만 음식을 보니 좀 이해됨</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>47</td>\n",
              "      <td>이 식당 알바 쓰는 듯</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Num                                             Review  Label\n",
              "1     2  적당히 좋은 소고기를 싸지 않은 가격에 맛볼 수 있다. 하지만 인기나 리뷰에 비해선...     -1\n",
              "5     6  신맛나지 않는 달콤한 탕수육도 맛있다 친절한 사장님도 추가 당분간 맛없는 배달짬뽕 ...      1\n",
              "6     7           식당규모가조금작아서점심시간에는대기했다가식사를해야됨니다.짬봉맛이정말좋아요.      1\n",
              "13   14  떡볶이 두 입 먹고 기절했습니다. 다시 깨어나서 쫄면 한 입 먹고 다시 기절했습니다...      1\n",
              "16   17                           이제 여기아닌 다른데서 탕수육 못먹겠음..       1\n",
              "34   35  좋은점. 중급 뷔페의 미덕을 충분히 갖췄다. 카테고리 위치가 적절해 동선이 꼬이지 ...      1\n",
              "38   39  칵테일 덕후 사장님께서 운영하시는 칵테일 바. 좋은 말로 얘기하면 알아서 해주는 칵...      1\n",
              "45   46                             주인이 거만하지만 음식을 보니 좀 이해됨      1\n",
              "46   47                                       이 식당 알바 쓰는 듯     -1"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 채점 간략화를 위해, 어려운 리뷰만 분리\n",
        "\n",
        "hard_reviews = reviews.iloc[[1,5,6,13,16,34,38,45,46]]\n",
        "hard_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f6e302ab",
      "metadata": {
        "id": "f6e302ab"
      },
      "outputs": [],
      "source": [
        "def evaluate(system_prompt, reviews):\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        (\"user\", '{review}')\n",
        "    ])\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "    for idx, review, label in zip(reviews['Num'],reviews['Review'], reviews['Label']):\n",
        "        print(f'#{idx} : ({correct}/{incorrect})')\n",
        "        print(review)\n",
        "        response = llm.invoke(prompt.format_messages(review=review)).content\n",
        "        print(response, '/', label)\n",
        "\n",
        "        if label == -1:\n",
        "            if '분류 결과: 부정' in response:\n",
        "                correct+=1\n",
        "            else:\n",
        "                incorrect += 1\n",
        "                print('Misclassification!')\n",
        "        else:\n",
        "            if '분류 결과: 긍정' in response:\n",
        "                correct+=1\n",
        "            else:\n",
        "                incorrect += 1\n",
        "                print('Misclassification!')\n",
        "        print()\n",
        "\n",
        "    print('Correct:', correct)\n",
        "    print('Incorrect:', incorrect)\n",
        "    print('Accuracy:', correct / (correct + incorrect))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "tV4ahlCo416a",
      "metadata": {
        "id": "tV4ahlCo416a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#2 : (0/0)\n",
            "적당히 좋은 소고기를 싸지 않은 가격에 맛볼 수 있다. 하지만 인기나 리뷰에 비해선 평범한 수준. 이런 맛과 가성비의 소고기집은 동네마다 아주아주 많다.\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "#6 : (1/0)\n",
            "신맛나지 않는 달콤한 탕수육도 맛있다 친절한 사장님도 추가 당분간 맛없는 배달짬뽕 먹을 생각하니 슬프다 사장님 쾌차하세요\n",
            "이 리뷰는 탕수육의 맛에 대한 긍정적인 언급이 있으며, 사장님에 대한 친절함도 언급하고 있습니다. 비록 배달짬뽕에 대한 불만이 있지만, 전반적으로 긍정적인 요소가 더 많습니다. \n",
            "\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#7 : (2/0)\n",
            "식당규모가조금작아서점심시간에는대기했다가식사를해야됨니다.짬봉맛이정말좋아요.\n",
            "짬뽕 맛이 정말 좋다는 긍정적인 언급이 있으며, 식당의 전문성도 느껴집니다. 대기하는 불편함이 언급되었지만, 맛에 대한 긍정적인 평가가 더 두드러집니다. \n",
            "\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#14 : (3/0)\n",
            "떡볶이 두 입 먹고 기절했습니다. 다시 깨어나서 쫄면 한 입 먹고 다시 기절했습니다. 사장님 들숨에 건강을 날숨에 재물을 기원합니다\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#17 : (4/0)\n",
            "이제 여기아닌 다른데서 탕수육 못먹겠음.. \n",
            "이 리뷰는 탕수육에 대한 강한 애정을 표현하고 있으며, 다른 곳에서는 이 맛을 느낄 수 없다는 점에서 긍정적인 감정을 드러내고 있습니다. 따라서 긍정적인 평가로 분류할 수 있습니다. \n",
            "\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#35 : (5/0)\n",
            "좋은점. 중급 뷔페의 미덕을 충분히 갖췄다. 카테고리 위치가 적절해 동선이 꼬이지 않는다. 광어와 연어, 젤라또가 훌륭했다. 개선할점. 와인 무제한에 화이트 와인도 서빙해야한다고 봄. 육류 중 한가지라도 구우면서 서빙되면 좋겠음.\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#39 : (6/0)\n",
            "칵테일 덕후 사장님께서 운영하시는 칵테일 바. 좋은 말로 얘기하면 알아서 해주는 칵테일, 다른 말로 하면 얼마인지 모르고 나중에 계산할 때 깜놀\n",
            "이 리뷰는 칵테일 바의 사장님이 전문성을 가지고 운영하고 있다는 점을 언급하고 있습니다. 그러나 가격에 대한 불만이 표현되어 있어 부정적인 요소도 포함되어 있습니다. 하지만 사장님의 전문성과 칵테일의 품질에 대한 긍정적인 암시가 있기 때문에 전체적으로 긍정적인 평가로 분류할 수 있습니다.\n",
            "\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#46 : (7/0)\n",
            "주인이 거만하지만 음식을 보니 좀 이해됨\n",
            "주인이 거만하다는 부정적인 언급이 있지만, 음식에 대한 긍정적인 평가가 암시되어 있습니다. 따라서 전체적으로 긍정적인 맥락으로 해석할 수 있습니다. \n",
            "\n",
            "분류 결과: 긍정 / 1\n",
            "\n",
            "#47 : (8/0)\n",
            "이 식당 알바 쓰는 듯\n",
            "이 리뷰는 식당에 대한 부정적인 인상을 주며, 알바를 쓰는 듯하다는 표현은 전문성이나 긍정적인 경험을 나타내지 않습니다. 따라서 부정적인 평가로 분류할 수 있습니다. \n",
            "\n",
            "분류 결과: 부정 / -1\n",
            "\n",
            "Correct: 9\n",
            "Incorrect: 0\n",
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "evaluate(good_system_prompt, hard_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "7NVaTxfY43qt",
      "metadata": {
        "id": "7NVaTxfY43qt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='분류 결과: 부정', response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 175, 'total_tokens': 182, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-b9dfc5fa-369d-42c3-a380-99a42dcede5b-0')"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 임의의 리뷰를 분석하고 싶다면?\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", good_system_prompt),\n",
        "    (\"user\", '{review}')\n",
        "])\n",
        "sample_review = ''''''\n",
        "\n",
        "llm.invoke(prompt.format_messages(review = sample_review))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "4NzhUHuDIotX",
      "metadata": {
        "id": "4NzhUHuDIotX"
      },
      "outputs": [],
      "source": [
        "# 좋은 프롬프트 예시\n",
        "example_system_prompt='''\n",
        "음식점에 대한 리뷰가 주어지면, 사용자의 의도를 파악하여\n",
        "50자 이내로 설명하고, 음식점에 대한 긍정/부정 여부를 분류하여 출력하세요.\n",
        "\n",
        "답변의 마지막에 분류 결과: 부정, 혹은 분류 결과: 긍정 을 출력하면 됩니다.\n",
        "위 형식을 지키고, 분류 결과 뒤에는 별도의 내용을 출력하지 마세요.\n",
        "---\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "SnSd6rVQIpXC",
      "metadata": {
        "id": "SnSd6rVQIpXC"
      },
      "outputs": [],
      "source": [
        "# 좋은 프롬프트 예시\n",
        "example_system_prompt2='''\n",
        "음식점에 대한 리뷰가 주어지면, 아래의 요소에 대한 견해를 각각 30자 이내로 출력하고,\n",
        "이를 바탕으로 '긍정/부정'중 하나로 최종 분류 결과를 출력하세요.\n",
        "각 요소에 대한 언급이 없는 경우 생략하세요.\n",
        "일반적으로, 부정에서 긍정으로 끝나는 경우 긍정 리뷰입니다.\n",
        "긍정에서 부정으로 끝나는 경우 부정 리뷰입니다.\n",
        "답변의 마지막에 분류 결과: 부정, 혹은 분류 결과: 긍정 을 출력하면 됩니다.\n",
        "위 형식을 지키고, 분류 결과 뒤에는 별도의 내용을 출력하지 마세요.\n",
        "---\n",
        "1. 음식\n",
        "2. 서비스\n",
        "3. 가격 대비 만족도\n",
        "4. 다른 식당과의 비교\n",
        "5. 분위기와 음악 등\n",
        "6. 분류 결과\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nx57dldQJnsU",
      "metadata": {
        "id": "nx57dldQJnsU"
      },
      "source": [
        "## 부록) GPT-4 VS GPT-3.5\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/NotoriousH2/img_container/assets/4037207/de39d8d4-e3bf-4a81-9a60-969fa240334f\" height=\"80%\" width=\"80%\">\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cbe4374",
      "metadata": {
        "id": "8cbe4374"
      },
      "source": [
        "## Few-Shot Prompting\n",
        "Few-Shot Prompt Template은 example을 쉽게 추가할 수 있도록 도와줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c1e86b21",
      "metadata": {
        "id": "c1e86b21"
      },
      "outputs": [],
      "source": [
        "# 예시 : Prompt Example 2개\n",
        "\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"question\": \"Who lived longer, Muhammad Ali or Alan Turing?\",\n",
        "        \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: How old was Muhammad Ali when he died?\n",
        "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
        "Follow up: How old was Alan Turing when he died?\n",
        "Intermediate answer: Alan Turing was 41 years old when he died.\n",
        "So the final answer is: Muhammad Ali\n",
        "\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
        "        \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: Who is the director of Jaws?\n",
        "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
        "Follow up: Where is Steven Spielberg from?\n",
        "Intermediate Answer: The United States.\n",
        "Follow up: Who is the director of Casino Royale?\n",
        "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
        "Follow up: Where is Martin Campbell from?\n",
        "Intermediate Answer: New Zealand.\n",
        "So the final answer is: No\n",
        "\"\"\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2232a1ba",
      "metadata": {
        "id": "2232a1ba"
      },
      "source": [
        "Example 데이터를 구성할 템플릿을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "5c3a7c48",
      "metadata": {
        "id": "5c3a7c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_prompt = PromptTemplate.from_template(\n",
        "    template=\"Question: {question}\\n{answer}\")\n",
        "\n",
        "print(example_prompt.format(**examples[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "581efd62",
      "metadata": {
        "id": "581efd62"
      },
      "source": [
        "위에서 만든 Examples와 템플릿, prefix와 suffix를 이용해 전체 템플릿을 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5d36e0c5",
      "metadata": {
        "id": "5d36e0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "질문-답변 형식의 예시가 주어집니다. 같은 방식으로 답변하세요.\n",
            "\n",
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate Answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate Answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "\n",
            "Question: This is Mar 2025. What is the current age of the director of a movie which got a best international film in Oscar in 2010?\n"
          ]
        }
      ],
      "source": [
        "prompt = FewShotPromptTemplate(\n",
        "\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "\n",
        "    prefix=\"질문-답변 형식의 예시가 주어집니다. 같은 방식으로 답변하세요.\",\n",
        "    suffix=\"Question: {input}\",\n",
        "    #prefix, suffix : Optional\n",
        "\n",
        "    input_variables=[\"input\"]\n",
        ")\n",
        "\n",
        "print(prompt.format(input=\"This is Mar 2025. What is the current age of the director of a movie which got a best international film in Oscar in 2010?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "22fb94a6",
      "metadata": {
        "id": "22fb94a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are follow up questions needed here: Yes.  \n",
            "Follow up: Which movie won the Best International Feature Film Oscar in 2010?  \n",
            "Intermediate Answer: The movie that won the Best International Feature Film Oscar in 2010 is \"The Secret in Their Eyes.\"  \n",
            "Follow up: Who is the director of \"The Secret in Their Eyes\"?  \n",
            "Intermediate Answer: The director of \"The Secret in Their Eyes\" is Juan José Campanella.  \n",
            "Follow up: When was Juan José Campanella born?  \n",
            "Intermediate Answer: Juan José Campanella was born on July 19, 1953.  \n",
            "Follow up: How old is Juan José Campanella as of March 2025?  \n",
            "Intermediate Answer: As of March 2025, Juan José Campanella is 71 years old.  \n",
            "So the final answer is: 71\n"
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0, max_tokens=1024)\n",
        "\n",
        "question = \"This is Mar 2025. What is the current age of the director of a movie which got a best international film in Oscar in 2010?\\n\"\n",
        "X = prompt.format(input=question)\n",
        "print(llm.invoke(X).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "e6732b28",
      "metadata": {
        "id": "e6732b28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are follow up questions needed here: Yes.  \n",
            "Follow up: 스티븐 스필버그의 영화 중 가장 많은 상을 받은 영화는 무엇인가요?  \n",
            "Intermediate Answer: 스티븐 스필버그의 영화 중 가장 많은 상을 받은 영화는 '쉰들러 리스트'입니다.  \n",
            "Follow up: '쉰들러 리스트'의 주연 배우는 누구인가요?  \n",
            "Intermediate Answer: '쉰들러 리스트'의 주연 배우는 리암 니슨입니다.  \n",
            "So the final answer is: 리암 니슨\n"
          ]
        }
      ],
      "source": [
        "question = \"스티븐 스필버그의 영화 중 가장 많은 상을 받은 영화의 주연 배우는?\"\n",
        "X = prompt.format(input=question)\n",
        "print(llm.invoke(X).content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
