{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBSFmmW0B_O2"
   },
   "source": [
    "# [실습] LangChain Tool과 Agent\n",
    "\n",
    "\n",
    "Agent는 사용자의 요청에 대해, 툴(Tool)로 표현되는 외부 모듈을 활용하여 문제를 해결하는 기능입니다.     \n",
    "\n",
    "Tool은 LLM이 답변을 출력하기 위해 활용할 수 있는 다양한 수단을 의미합니다.   \n",
    "LLM은 Tool을 사용하기 위해 Tool 이름과 Argument를 생성하는데요.\n",
    "\n",
    "이 Tool 실행을 자동화하여 LLM을 반복적으로 실행하여 최종 단계에 도달하는 방법이 Agent입니다.\n",
    "\n",
    "<br><br><br>\n",
    "Agent의 작동 방식은 아래와 같습니다.\n",
    "\n",
    "1. 에이전트에 입력이 주어지면, 툴을 사용하는 액션(Action)을 결정합니다.\n",
    "1. 툴의 사용 결과가 에이전트에 전달되면, 이를 활용하여 다음 액션을 정합니다.\n",
    "1. 이후, 원하는 결과에 도달할 때까지 반복됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MHjWGmc3i5fU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.7-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-community\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting langgraph\n",
      "  Using cached langgraph-0.3.5-py3-none-any.whl (131 kB)\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "Collecting wikipedia\n",
      "  Using cached wikipedia-1.4.0-py3-none-any.whl\n",
      "Collecting tavily-python\n",
      "  Using cached tavily_python-0.5.1-py3-none-any.whl (43 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Collecting langchain-experimental\n",
      "  Using cached langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.41\n",
      "  Downloading langchain_core-0.3.41-py3-none-any.whl (415 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.1/415.1 KB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langsmith<0.4,>=0.1.17\n",
      "  Downloading langsmith-0.3.11-py3-none-any.whl (335 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.3/335.3 KB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<3,>=2\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Collecting PyYAML>=5.3\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 KB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3.0.0,>=2.7.4\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken<1,>=0.7\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openai<2.0.0,>=1.58.1\n",
      "  Downloading openai-1.65.3-py3-none-any.whl (472 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 KB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Collecting numpy<3,>=1.26.2\n",
      "  Downloading numpy-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42\n",
      "  Using cached langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10\n",
      "  Using cached langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.1\n",
      "  Using cached langgraph_prebuilt-0.1.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./llm/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
      "Collecting grpcio>=1.58.0\n",
      "  Using cached grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "Collecting tokenizers>=0.13.2\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson>=3.9.12\n",
      "  Using cached orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Collecting chroma-hnswlib==0.7.6\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting uvicorn[standard]>=0.18.3\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mmh3>=4.0.1\n",
      "  Using cached mmh3-5.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)\n",
      "Collecting pypika>=0.48.9\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Collecting posthog>=2.4.0\n",
      "  Downloading posthog-3.18.1-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting build>=1.0.3\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting bcrypt>=4.0.1\n",
      "  Using cached bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
      "Collecting tqdm>=4.65.0\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime>=1.14.1\n",
      "  Using cached onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "Collecting typer>=0.9.0\n",
      "  Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Collecting opentelemetry-api>=1.2.0\n",
      "  Using cached opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0\n",
      "  Using cached opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
      "Collecting kubernetes>=28.1.0\n",
      "  Using cached kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "Collecting fastapi>=0.95.2\n",
      "  Using cached fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
      "Collecting overrides>=7.3.1\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting httpx>=0.27.0\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-instrumentation-fastapi>=0.41b0\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.0/186.0 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./llm/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./llm/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 KB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting propcache>=0.2.0\n",
      "  Using cached propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Using cached yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.8-py3-none-any.whl (15 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Collecting pyproject_hooks\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting tomli>=1.1.0\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0\n",
      "  Downloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth>=1.0.1\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Collecting oauthlib>=3.2.2\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Collecting durationpy>=0.7\n",
      "  Using cached durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in ./llm/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Collecting requests-oauthlib\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting urllib3>=1.24.2\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonpatch<2.0,>=1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting msgpack<2.0.0,>=1.1.0\n",
      "  Using cached msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-6.30.0-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 KB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 KB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting deprecated>=1.2.6\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting importlib-metadata<=8.5.0,>=6.0\n",
      "  Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting opentelemetry-proto==1.30.0\n",
      "  Using cached opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
      "Collecting googleapis-common-protos~=1.52\n",
      "  Downloading googleapis_common_protos-1.69.0-py2.py3-none-any.whl (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.7/169.7 KB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-common==1.30.0\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-util-http==0.51b0\n",
      "  Using cached opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
      "Collecting opentelemetry-instrumentation==0.51b0\n",
      "  Using cached opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.51b0\n",
      "  Using cached opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.51b0\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0\n",
      "  Using cached wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Collecting asgiref~=3.0\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Collecting backoff>=1.10.0\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.21.0\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.1/146.1 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in ./llm/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 KB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4\n",
      "  Using cached huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting click>=8.0.0\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0\n",
      "  Using cached uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Collecting websockets>=10.4\n",
      "  Downloading websockets-15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (180 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.9/180.9 KB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13\n",
      "  Using cached watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "Collecting httptools>=0.6.3\n",
      "  Using cached httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./llm/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Collecting zipp>=3.20\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pypika, mpmath, monotonic, flatbuffers, durationpy, zstandard, zipp, wrapt, websockets, websocket-client, uvloop, urllib3, tqdm, tomli, tenacity, sympy, soupsieve, sniffio, shellingham, regex, PyYAML, python-dotenv, pyproject_hooks, pypdf, pyparsing, pydantic-core, pyasn1, protobuf, propcache, pillow, overrides, orjson, opentelemetry-util-http, oauthlib, numpy, mypy-extensions, multidict, msgpack, mmh3, mdurl, marshmallow, kiwisolver, jsonpointer, jiter, importlib-resources, idna, humanfriendly, httpx-sse, httptools, h11, grpcio, greenlet, fsspec, frozenlist, fonttools, filelock, distro, cycler, click, charset-normalizer, certifi, cachetools, bcrypt, backoff, attrs, async-timeout, asgiref, annotated-types, aiohappyeyeballs, yarl, uvicorn, typing-inspect, SQLAlchemy, rsa, requests, pydantic, pyasn1-modules, opentelemetry-proto, markdown-it-py, jsonpatch, importlib-metadata, httpcore, googleapis-common-protos, deprecated, contourpy, coloredlogs, chroma-hnswlib, build, beautifulsoup4, anyio, aiosignal, wikipedia, watchfiles, tiktoken, starlette, rich, requests-toolbelt, requests-oauthlib, pydantic-settings, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, matplotlib, huggingface-hub, httpx, google-auth, dataclasses-json, aiohttp, typer, tokenizers, tavily-python, opentelemetry-semantic-conventions, openai, langsmith, langgraph-sdk, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langgraph-checkpoint, langchain-text-splitters, langchain-openai, opentelemetry-instrumentation-fastapi, langgraph-prebuilt, langchain, langgraph, langchain-community, chromadb, langchain-experimental\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.8 aiohttp-3.11.13 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 asgiref-3.8.1 async-timeout-4.0.3 attrs-25.1.0 backoff-2.2.1 bcrypt-4.3.0 beautifulsoup4-4.13.3 build-1.2.2.post1 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 chroma-hnswlib-0.7.6 chromadb-0.6.3 click-8.1.8 coloredlogs-15.0.1 contourpy-1.3.1 cycler-0.12.1 dataclasses-json-0.6.7 deprecated-1.2.18 distro-1.9.0 durationpy-0.9 fastapi-0.115.11 filelock-3.17.0 flatbuffers-25.2.10 fonttools-4.56.0 frozenlist-1.5.0 fsspec-2025.2.0 google-auth-2.38.0 googleapis-common-protos-1.69.0 greenlet-3.1.1 grpcio-1.70.0 h11-0.14.0 httpcore-1.0.7 httptools-0.6.4 httpx-0.28.1 httpx-sse-0.4.0 huggingface-hub-0.29.1 humanfriendly-10.0 idna-3.10 importlib-metadata-8.5.0 importlib-resources-6.5.2 jiter-0.8.2 jsonpatch-1.33 jsonpointer-3.0.0 kiwisolver-1.4.8 kubernetes-32.0.1 langchain-0.3.20 langchain-community-0.3.19 langchain-core-0.3.41 langchain-experimental-0.3.4 langchain-openai-0.3.7 langchain-text-splitters-0.3.6 langgraph-0.3.5 langgraph-checkpoint-2.0.16 langgraph-prebuilt-0.1.1 langgraph-sdk-0.1.53 langsmith-0.3.11 markdown-it-py-3.0.0 marshmallow-3.26.1 matplotlib-3.10.1 mdurl-0.1.2 mmh3-5.1.0 monotonic-1.6 mpmath-1.3.0 msgpack-1.1.0 multidict-6.1.0 mypy-extensions-1.0.0 numpy-2.2.3 oauthlib-3.2.2 onnxruntime-1.20.1 openai-1.65.3 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 orjson-3.10.15 overrides-7.7.0 pillow-11.1.0 posthog-3.18.1 propcache-0.3.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.8.1 pyparsing-3.2.1 pypdf-5.3.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 regex-2024.11.6 requests-2.32.3 requests-oauthlib-2.0.0 requests-toolbelt-1.0.0 rich-13.9.4 rsa-4.9 shellingham-1.5.4 sniffio-1.3.1 soupsieve-2.6 starlette-0.46.0 sympy-1.13.3 tavily-python-0.5.1 tenacity-9.0.0 tiktoken-0.9.0 tokenizers-0.21.0 tomli-2.2.1 tqdm-4.67.1 typer-0.15.2 typing-inspect-0.9.0 urllib3-2.3.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 websocket-client-1.8.0 websockets-15.0 wikipedia-1.4.0 wrapt-1.17.2 yarl-1.18.3 zipp-3.21.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install langchain langchain-openai langchain-community langgraph pypdf chromadb wikipedia tavily-python wikipedia matplotlib langchain-experimental langchain_chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6W3hW1HngUw"
   },
   "source": [
    "## OpenAI API로 Agent 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "isPOel4VngUx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "with open(\"api_key.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "api_key = config[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# OPENAI API KEY 설정\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRfV-aKKngUx"
   },
   "source": [
    "Agent는 포맷에 맞는 입/출력의 반복을 통해 문제를 해결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "630LrjNvngUx"
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    # __init__ : Agent 클래스가 생성될 때 호출되는 함수\n",
    "    def __init__(self, system_prompt=\"\"):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.messages = []\n",
    "        # message를 저장\n",
    "\n",
    "        self.messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    # __call__ : Agent 클래스가 호출될 때 호출되는 함수\n",
    "    # message와 result를 생성하고 이를 messages에 추가\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    # execute : 현재까지의 message로 답변 생성\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4o-mini\",\n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VGvt-8UingUx"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "당신은 질문에 답변하기 위해 Thought, Action, PAUSE, Observation의 루프를 사용하는 인공지능 비서입니다.\n",
    "루프의 끝에는 답변을 출력합니다.\n",
    "질문에 대한 답변을 설명하기 위해 Thought를 사용합니다.\n",
    "Action을 사용하여 사용 가능한 작업 중 하나를 실행하고 PAUSE를 반환합니다.\n",
    "Observation은 해당 작업을 실행한 결과입니다.\n",
    "\n",
    "사용 가능한 작업은 다음과 같습니다:\n",
    "\n",
    "\n",
    "search_number:\n",
    "예시) search_number: 전우치\n",
    "연락처 목록에서 이름을 검색하고 해당 이름의 전화번호를 반환합니다.\n",
    "\n",
    "send_message:\n",
    "예시) send_message: 010-1234-5678\n",
    "전화번호를 사용하여 메시지를 보내고 메시지를 성공적으로 보냈다는 메시지를 반환합니다.\n",
    "\n",
    "다음은 예시 사용 사례입니다:\n",
    "\n",
    "Question: 홍길동의 전화번호는 무엇입니까?\n",
    "Thought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.\n",
    "Action: search_number: 홍길동\n",
    "PAUSE\n",
    "\n",
    "그 이후 작업의 결과와 함께 다시 호출됩니다.\n",
    "Observation은 외부에서 입력되는 메시지입니다. 임의로 생성할 수 없습니다.:\n",
    "\n",
    "Observation: 010-4539-2918\n",
    "\n",
    "이제 답변을 출력합니다:\n",
    "\n",
    "Answer: 홍길동의 전화번호는 010-4539-2918입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8rWq6xzEngUx"
   },
   "outputs": [],
   "source": [
    "def send_message(recipient):\n",
    "    return recipient+ \"에 메시지를 성공적으로 보냈습니다.\"\n",
    "\n",
    "def search_number(name):\n",
    "    if name == '홍길동':\n",
    "        return(\"010-4539-2918\")\n",
    "    elif name == '전우치':\n",
    "        return (\"010-1234-5678\")\n",
    "    elif name == '이순신':\n",
    "        return(\"010-9876-5432\")\n",
    "known_actions = {\n",
    "    \"send_message\": send_message,\n",
    "    \"search_number\": search_number\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fOgCUxMBngUy"
   },
   "outputs": [],
   "source": [
    "abot = Agent(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GUQ7T8QmngUy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.  \n",
      "Action: search_number: 홍길동  \n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = abot(\"홍길동의 전화번호는 무엇입니까?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JAzZEy82ngUy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'010-4539-2918'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = search_number(\"홍길동\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TRH72eP0ngUy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Observation: 010-4539-2918'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)\n",
    "next_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QHw5rL9dngUy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 홍길동의 전화번호는 010-4539-2918입니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RNEu6fQNngUy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n당신은 질문에 답변하기 위해 Thought, Action, PAUSE, Observation의 루프를 사용하는 인공지능 비서입니다.\\n루프의 끝에는 답변을 출력합니다.\\n질문에 대한 답변을 설명하기 위해 Thought를 사용합니다.\\nAction을 사용하여 사용 가능한 작업 중 하나를 실행하고 PAUSE를 반환합니다.\\nObservation은 해당 작업을 실행한 결과입니다.\\n\\n사용 가능한 작업은 다음과 같습니다:\\n\\n\\nsearch_number:\\n예시) search_number: 전우치\\n연락처 목록에서 이름을 검색하고 해당 이름의 전화번호를 반환합니다.\\n\\nsend_message:\\n예시) send_message: 010-1234-5678\\n전화번호를 사용하여 메시지를 보내고 메시지를 성공적으로 보냈다는 메시지를 반환합니다.\\n\\n다음은 예시 사용 사례입니다:\\n\\nQuestion: 홍길동의 전화번호는 무엇입니까?\\nThought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.\\nAction: search_number: 홍길동\\nPAUSE\\n\\n그 이후 작업의 결과와 함께 다시 호출됩니다.\\nObservation은 외부에서 입력되는 메시지입니다. 임의로 생성할 수 없습니다.:\\n\\nObservation: 010-4539-2918\\n\\n이제 답변을 출력합니다:\\n\\nAnswer: 홍길동의 전화번호는 010-4539-2918입니다.\\n'},\n",
       " {'role': 'user', 'content': '홍길동의 전화번호는 무엇입니까?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.  \\nAction: search_number: 홍길동  \\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: 010-4539-2918'},\n",
       " {'role': 'assistant', 'content': 'Answer: 홍길동의 전화번호는 010-4539-2918입니다.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y30n-LGQngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 전우치에게 메시지를 보내기 위해 먼저 그의 전화번호를 찾아야 한다. 따라서 search_number 작업을 사용해야 한다.  \n",
      "Action: search_number: 전우치  \n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "abot = Agent(prompt)\n",
    "question = \"\"\"전우치에게 메시지 보내 주세요.\"\"\"\n",
    "print(abot(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oWjWILgpngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 010-1234-5678\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(search_number(\"전우치\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SOGsisFzngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 전우치의 전화번호를 찾았으므로, 이제 해당 번호로 메시지를 보내야 한다.  \n",
      "Action: send_message: 010-1234-5678  \n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "print(abot(next_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "5AHnTzqCngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: 010-1234-5678에 메시지를 성공적으로 보냈습니다.\n"
     ]
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(send_message(\"010-1234-5678\"))\n",
    "print(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Tu-Ov6_wngUz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 전우치에게 메시지를 성공적으로 보냈습니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot(next_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rEuRxo98ngUz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n당신은 질문에 답변하기 위해 Thought, Action, PAUSE, Observation의 루프를 사용하는 인공지능 비서입니다.\\n루프의 끝에는 답변을 출력합니다.\\n질문에 대한 답변을 설명하기 위해 Thought를 사용합니다.\\nAction을 사용하여 사용 가능한 작업 중 하나를 실행하고 PAUSE를 반환합니다.\\nObservation은 해당 작업을 실행한 결과입니다.\\n\\n사용 가능한 작업은 다음과 같습니다:\\n\\n\\nsearch_number:\\n예시) search_number: 전우치\\n연락처 목록에서 이름을 검색하고 해당 이름의 전화번호를 반환합니다.\\n\\nsend_message:\\n예시) send_message: 010-1234-5678\\n전화번호를 사용하여 메시지를 보내고 메시지를 성공적으로 보냈다는 메시지를 반환합니다.\\n\\n다음은 예시 사용 사례입니다:\\n\\nQuestion: 홍길동의 전화번호는 무엇입니까?\\nThought: 홍길동의 전화번호를 찾기 위해 search_number 작업을 사용해야 한다.\\nAction: search_number: 홍길동\\nPAUSE\\n\\n그 이후 작업의 결과와 함께 다시 호출됩니다.\\nObservation은 외부에서 입력되는 메시지입니다. 임의로 생성할 수 없습니다.:\\n\\nObservation: 010-4539-2918\\n\\n이제 답변을 출력합니다:\\n\\nAnswer: 홍길동의 전화번호는 010-4539-2918입니다.\\n'},\n",
       " {'role': 'user', 'content': '전우치에게 메시지 보내 주세요.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: 전우치에게 메시지를 보내기 위해 먼저 그의 전화번호를 찾아야 한다. 따라서 search_number 작업을 사용해야 한다.  \\nAction: search_number: 전우치  \\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: 010-1234-5678'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: 전우치의 전화번호를 찾았으므로, 이제 해당 번호로 메시지를 보내야 한다.  \\nAction: send_message: 010-1234-5678  \\nPAUSE'},\n",
       " {'role': 'user', 'content': 'Observation: 010-1234-5678에 메시지를 성공적으로 보냈습니다.'},\n",
       " {'role': 'assistant', 'content': 'Answer: 전우치에게 메시지를 성공적으로 보냈습니다.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Zv3XohCSngUz"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "action_re = re.compile('^Action: (\\w+): (.*)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "K0EM9MMcngUz"
   },
   "outputs": [],
   "source": [
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = bot(next_prompt)\n",
    "        print(result)\n",
    "        actions = [\n",
    "            action_re.match(a)\n",
    "            for a in result.split('\\n')\n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "        if actions:\n",
    "            action, action_input = actions[0].groups()\n",
    "            print(\" -- 실행중: {} {}\".format(action, action_input))\n",
    "            observation = known_actions[action](action_input)\n",
    "            print(\"Observation:\", observation)\n",
    "            next_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UZdyuathngUz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: 전우치와 홍길동의 전화번호를 먼저 찾아야 한다. 이를 위해 search_number 작업을 사용해야 한다. \n",
      "\n",
      "Action: search_number: 전우치\n",
      "PAUSE\n",
      " -- 실행중: search_number 전우치\n",
      "Observation: 010-1234-5678\n",
      "Thought: 전우치의 전화번호를 찾았으니, 이제 홍길동의 전화번호를 검색해야 한다. \n",
      "\n",
      "Action: search_number: 홍길동\n",
      "PAUSE\n",
      " -- 실행중: search_number 홍길동\n",
      "Observation: 010-4539-2918\n",
      "Thought: 전우치와 홍길동의 전화번호를 모두 찾았다. 이제 두 사람에게 메시지를 보내야 한다. \n",
      "\n",
      "Action: send_message: 010-1234-5678\n",
      "PAUSE\n",
      " -- 실행중: send_message 010-1234-5678\n",
      "Observation: 010-1234-5678에 메시지를 성공적으로 보냈습니다.\n",
      "Thought: 전우치에게 메시지를 성공적으로 보냈으니, 이제 홍길동에게 메시지를 보내야 한다. \n",
      "\n",
      "Action: send_message: 010-4539-2918\n",
      "PAUSE\n",
      " -- 실행중: send_message 010-4539-2918\n",
      "Observation: 010-4539-2918에 메시지를 성공적으로 보냈습니다.\n",
      "Answer: 전우치와 홍길동에게 메시지를 성공적으로 보냈습니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"전우치와 홍길동에게 메시지 보내 줘.\"\"\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yjVCEDz_2iK"
   },
   "source": [
    "<br><br><br>\n",
    "# LangChain에서 Tool 사용하기\n",
    "\n",
    "이제, 해당 기능을 LangChain에서 구현해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGv8IR1n_2iK"
   },
   "source": [
    "총 4개의 툴을 사용합니다.\n",
    "\n",
    "1. wiki : 위키피디아 쿼리 검색 툴\n",
    "2. tavily : TavilyAI 웹 검색 툴\n",
    "3. repl_tool : Python REPL 실행 툴\n",
    "4. multiply : 단순 곱하기 커스텀 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "62b-4iUG_2iK"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', max_tokens=1024, temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUQffEYW_2iK"
   },
   "source": [
    "Tool 1: Wikipedia 검색 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dlcYIYRS_2iK"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=5000)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper) # 위키피디아 쿼리 검색 툴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2iCqf98j_2iK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/config/workspace/LLM/Langchain/llm/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /config/workspace/LLM/Langchain/llm/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) refers to the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
      "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
      "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\n",
      "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism throughout its history, followed by periods of disappointment and loss of funding, known as AI winters. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s many billions of dollars were being invested in AI and the field experienced rapid ongoing progress in what has become known as the AI boom. The emergence of advanced generative AI in the midst of the AI boom and its ability to create and modify content exposed several unintended consequences and harms in the present and raised concerns about the risks of AI and its long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
      "\n",
      "Page: .ai\n",
      "Summary: .ai is the Internet country code top-level domain (ccTLD) for Anguilla, a British Overseas Territory in the Caribbean. It is administered by the government of Anguilla.\n",
      "It is a popular domain hack with companies and projects related to the artificial intelligence industry (AI).\n",
      "Google's ad targeting treats .ai as a generic top-level domain (gTLD) because \"users and website owners frequently see [the domain] as being more generic than country-targeted.\"\n",
      "Identity Digital began managing the domain as of January 2025.\n"
     ]
    }
   ],
   "source": [
    "print(wiki.invoke({\"query\": \"A.I\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUPAXX2-_2iK"
   },
   "source": [
    "Tavily: 웹 검색 툴   \n",
    "\n",
    "Tavily AI(https://app.tavily.com/home) 는 검색 결과에 AI 기반 요약을 포함하며,    \n",
    " 월 1,000개의 API 호출을 무료로 지원합니다.\n",
    "\n",
    "- 네이버/구글/유튜브 검색을 지원하는  SerpAPI(https://serpapi.com/)    \n",
    "(무료 라이센스 월 150회 검색)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "kH7JtFWi_2iL"
   },
   "outputs": [],
   "source": [
    "# To install: pip install tavily-python\n",
    "from tavily import TavilyClient\n",
    "import json\n",
    "\n",
    "with open(\"api_key.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "tavily_api_key = config[\"TAVILY_API_KEY\"]\n",
    "\n",
    "# OPENAI API KEY 설정\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = tavily_api_key\n",
    "tavily = TavilySearchResults(max_results = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "yuXUoiOm_2iL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Introducing Claude 3.5 Sonnet - Anthropic', 'url': 'https://www.anthropic.com/news/claude-3-5-sonnet', 'content': 'Introducing Claude 3.5 Sonnet \\\\ Anthropic Claude Claude 3.5 Sonnet Claude 3.5 Sonnet raises the industry bar for intelligence, outperforming competitor models and Claude 3 Opus on a wide range of evaluations, with the speed and cost of our mid-tier model, Claude 3 Sonnet. This performance boost, combined with cost-effective pricing, makes Claude 3.5 Sonnet ideal for complex tasks such as context-sensitive customer support and orchestrating multi-step workflows. Claude 3.5 Sonnet is our strongest vision model yet, surpassing Claude 3 Opus on standard vision benchmarks. It’s just the beginning of a broader vision for Claude.ai, which will soon expand to support team collaboration. You can submit feedback on Claude 3.5 Sonnet directly in-product to inform our development roadmap and help our teams to improve your experience. Claude', 'score': 0.8958969}, {'title': 'Announcing Claude 3.5 Sonnet on the Clarity Platform | AI at Yale', 'url': 'https://ai.yale.edu/posts/2025-02-10-announcing-claude-35-sonnet-on-the-clarity-platform', 'content': 'Announcing Claude 3.5 Sonnet on the Clarity Platform | AI at Yale Announcing Claude 3.5 Sonnet on the Clarity Platform Claude 3.5 Sonnet is now available on the Clarity Platform, offering a new generative AI model that supports brainstorming, creative and academic writing, code generation, and more. The Clarity Platform now features Claude 3.5 Sonnet, an agent that generates text responses using Anthropic’s Claude 3.5 Sonnet model and images using DALL·E 3. The selection of AI models available within Clarity allows members of the Yale community to compare and evaluate different tools while exploring their practical applications. Because it is an agent within the Clarity Platform, Claude 3.5 Sonnet is appropriate for use with low, medium, and most high-risk data, except for Electronic Protected Health Information (ePHI).', 'score': 0.8863518}, {'title': 'Claude 3.7 Sonnet - Anthropic', 'url': 'https://www.anthropic.com/claude/sonnet', 'content': \"For developers interested in building custom AI solutions with Claude 3.5 Sonnet, it is available on the Anthropic API, Amazon Bedrock, and Google Cloud's Vertex AI. Claude 3.5 Sonnet is the first frontier AI model to reliably use computers in this way—albeit experimentally in public beta—and we expect the capability to improve over time. With the new Claude 3.5 Sonnet, we’re entering a new era of AI-powered DevSecOps. Across our use cases, we’re seeing 5-10% improvements over the previous version. The new Claude 3.5 Sonnet with computer use is a leap forward in autonomous AI. When should I use Claude 3.5 Sonnet? We recommend Claude 3.5 Sonnet for critical use cases where you want frontier intelligence, like customer-facing AI experiences.\", 'score': 0.8827621}, {'title': 'What Is Claude 3.5 Sonnet? How It Works, Use Cases, and Artifacts', 'url': 'https://www.datacamp.com/blog/claude-sonnet-anthropic', 'content': 'Claude 3.5 Sonnet outperforms GPT-4o and Gemini Pro 1.5 in several benchmarks and introduces a cool new feature: Artifacts. Claude 3.5 Sonnet not only beats GPT-4o and Gemini 1.5 Pro in several benchmarks but also introduces a new awesome feature called Artifacts. Once activated, you can trigger the feature by asking Claude to generate content that can be displayed in an Artifact, such as code, data visualizations, or even mockups. What are Artifacts in Claude 3.5 Sonnet? Artifacts is a new feature in Claude 3.5 Sonnet that allows you to interact with and manipulate outputs from the model, such as code, text, or data, directly within the chat interface. How can I use Artifacts in Claude 3.5 Sonnet? Explore Claude Artifacts, a new way to work with AI-generated content.', 'score': 0.82795376}, {'title': \"Anthropic's Claude 3.5 Sonnet now available in Snowflake Cortex AI\", 'url': 'https://www.snowflake.com/en/blog/anthropic-claude-sonnet-cortex-ai/', 'content': \"Build RAG and Agent-based AI Apps with Anthropic’s Claude 3.5 Sonnet in Snowflake Cortex AI Snowflake launched Cortex AI, a suite of integrated features and services that include fully managed LLM inference, fine-tuning and RAG for structured and unstructured data, to enable customers to quickly analyze unstructured data alongside their structured data and expedite the building of AI apps. Gaining access to Anthropic's industry-leading Claude 3.5 models within Snowflake Cortex AI empowers us to more quickly unlock value for our shared clients in a way that is secure and governed. Claude 3.5 Sonnet in Cortex AI makes it easy to build apps alongside your data with other features such as Streamlit (frontend development in Python) and Cortex Search (RAG engine with integrated embedding generation, vector management and hybrid search).\", 'score': 0.8016413}]\n"
     ]
    }
   ],
   "source": [
    "print(tavily.invoke('Claude 3.5 Sonnet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx13u3yo_2iL"
   },
   "source": [
    "PythonREPL : 파이썬 코드 작성 및 실행 툴  \n",
    "\n",
    "\n",
    "PythonREPL은 Code Interpreter와 다르게, 로컬 환경에서 실행됩니다.   \n",
    "임의의 파이썬 코드를 실행할 수 있으므로, 실행에 주의가 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "z72ks4P8_2iL"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python_repl = PythonREPL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "p-z8e5mO_2iL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_code = \"for i in range(10): print(i)\"\n",
    "\n",
    "python_repl.run(example_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcCA0IeI_2iL"
   },
   "source": [
    "`python_repl.run` 은 아래와 같이 툴로 변환 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "ujZtq2RE_2iL"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
    "    func=python_repl.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "MAegQEyg_2iL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl_tool.invoke({\"input\": example_code})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3EUVA56_2iP"
   },
   "source": [
    "커스텀 함수를 툴로 변환하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "jMnqg0ce_2iP"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(x:int, y:int) -> int:\n",
    "    \"x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.\"\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "_p9xdR7J_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = {'x':10, 'y':99}\n",
    "\n",
    "multiply.invoke(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "labB_kjA_2iQ"
   },
   "source": [
    "위에서 만든 툴을 리스트로 묶고, LLM에 binding합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "TvOHmM7C_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='multiply', description='x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x7ff3cac3fbe0>),\n",
       " WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/config/workspace/LLM/Langchain/llm/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=1000)),\n",
       " TavilySearchResults(api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'))),\n",
       " Tool(name='python_repl', description='A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.', func=<bound method PythonREPL.run of PythonREPL(globals={'__builtins__': {'__name__': 'builtins', '__doc__': \"Built-in functions, exceptions, and other objects.\\n\\nNoteworthy: None is the `nil' object; Ellipsis represents `...' in slices.\", '__package__': '', '__loader__': <class '_frozen_importlib.BuiltinImporter'>, '__spec__': ModuleSpec(name='builtins', loader=<class '_frozen_importlib.BuiltinImporter'>, origin='built-in'), '__build_class__': <built-in function __build_class__>, '__import__': <built-in function __import__>, 'abs': <built-in function abs>, 'all': <built-in function all>, 'any': <built-in function any>, 'ascii': <built-in function ascii>, 'bin': <built-in function bin>, 'breakpoint': <built-in function breakpoint>, 'callable': <built-in function callable>, 'chr': <built-in function chr>, 'compile': <built-in function compile>, 'delattr': <built-in function delattr>, 'dir': <built-in function dir>, 'divmod': <built-in function divmod>, 'eval': <built-in function eval>, 'exec': <built-in function exec>, 'format': <built-in function format>, 'getattr': <built-in function getattr>, 'globals': <built-in function globals>, 'hasattr': <built-in function hasattr>, 'hash': <built-in function hash>, 'hex': <built-in function hex>, 'id': <built-in function id>, 'input': <bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7ff40a629750>>, 'isinstance': <built-in function isinstance>, 'issubclass': <built-in function issubclass>, 'iter': <built-in function iter>, 'aiter': <built-in function aiter>, 'len': <built-in function len>, 'locals': <built-in function locals>, 'max': <built-in function max>, 'min': <built-in function min>, 'next': <built-in function next>, 'anext': <built-in function anext>, 'oct': <built-in function oct>, 'ord': <built-in function ord>, 'pow': <built-in function pow>, 'print': <built-in function print>, 'repr': <built-in function repr>, 'round': <built-in function round>, 'setattr': <built-in function setattr>, 'sorted': <built-in function sorted>, 'sum': <built-in function sum>, 'vars': <built-in function vars>, 'None': None, 'Ellipsis': Ellipsis, 'NotImplemented': NotImplemented, 'False': False, 'True': True, 'bool': <class 'bool'>, 'memoryview': <class 'memoryview'>, 'bytearray': <class 'bytearray'>, 'bytes': <class 'bytes'>, 'classmethod': <class 'classmethod'>, 'complex': <class 'complex'>, 'dict': <class 'dict'>, 'enumerate': <class 'enumerate'>, 'filter': <class 'filter'>, 'float': <class 'float'>, 'frozenset': <class 'frozenset'>, 'property': <class 'property'>, 'int': <class 'int'>, 'list': <class 'list'>, 'map': <class 'map'>, 'object': <class 'object'>, 'range': <class 'range'>, 'reversed': <class 'reversed'>, 'set': <class 'set'>, 'slice': <class 'slice'>, 'staticmethod': <class 'staticmethod'>, 'str': <class 'str'>, 'super': <class 'super'>, 'tuple': <class 'tuple'>, 'type': <class 'type'>, 'zip': <class 'zip'>, '__debug__': True, 'BaseException': <class 'BaseException'>, 'Exception': <class 'Exception'>, 'TypeError': <class 'TypeError'>, 'StopAsyncIteration': <class 'StopAsyncIteration'>, 'StopIteration': <class 'StopIteration'>, 'GeneratorExit': <class 'GeneratorExit'>, 'SystemExit': <class 'SystemExit'>, 'KeyboardInterrupt': <class 'KeyboardInterrupt'>, 'ImportError': <class 'ImportError'>, 'ModuleNotFoundError': <class 'ModuleNotFoundError'>, 'OSError': <class 'OSError'>, 'EnvironmentError': <class 'OSError'>, 'IOError': <class 'OSError'>, 'EOFError': <class 'EOFError'>, 'RuntimeError': <class 'RuntimeError'>, 'RecursionError': <class 'RecursionError'>, 'NotImplementedError': <class 'NotImplementedError'>, 'NameError': <class 'NameError'>, 'UnboundLocalError': <class 'UnboundLocalError'>, 'AttributeError': <class 'AttributeError'>, 'SyntaxError': <class 'SyntaxError'>, 'IndentationError': <class 'IndentationError'>, 'TabError': <class 'TabError'>, 'LookupError': <class 'LookupError'>, 'IndexError': <class 'IndexError'>, 'KeyError': <class 'KeyError'>, 'ValueError': <class 'ValueError'>, 'UnicodeError': <class 'UnicodeError'>, 'UnicodeEncodeError': <class 'UnicodeEncodeError'>, 'UnicodeDecodeError': <class 'UnicodeDecodeError'>, 'UnicodeTranslateError': <class 'UnicodeTranslateError'>, 'AssertionError': <class 'AssertionError'>, 'ArithmeticError': <class 'ArithmeticError'>, 'FloatingPointError': <class 'FloatingPointError'>, 'OverflowError': <class 'OverflowError'>, 'ZeroDivisionError': <class 'ZeroDivisionError'>, 'SystemError': <class 'SystemError'>, 'ReferenceError': <class 'ReferenceError'>, 'MemoryError': <class 'MemoryError'>, 'BufferError': <class 'BufferError'>, 'Warning': <class 'Warning'>, 'UserWarning': <class 'UserWarning'>, 'EncodingWarning': <class 'EncodingWarning'>, 'DeprecationWarning': <class 'DeprecationWarning'>, 'PendingDeprecationWarning': <class 'PendingDeprecationWarning'>, 'SyntaxWarning': <class 'SyntaxWarning'>, 'RuntimeWarning': <class 'RuntimeWarning'>, 'FutureWarning': <class 'FutureWarning'>, 'ImportWarning': <class 'ImportWarning'>, 'UnicodeWarning': <class 'UnicodeWarning'>, 'BytesWarning': <class 'BytesWarning'>, 'ResourceWarning': <class 'ResourceWarning'>, 'ConnectionError': <class 'ConnectionError'>, 'BlockingIOError': <class 'BlockingIOError'>, 'BrokenPipeError': <class 'BrokenPipeError'>, 'ChildProcessError': <class 'ChildProcessError'>, 'ConnectionAbortedError': <class 'ConnectionAbortedError'>, 'ConnectionRefusedError': <class 'ConnectionRefusedError'>, 'ConnectionResetError': <class 'ConnectionResetError'>, 'FileExistsError': <class 'FileExistsError'>, 'FileNotFoundError': <class 'FileNotFoundError'>, 'IsADirectoryError': <class 'IsADirectoryError'>, 'NotADirectoryError': <class 'NotADirectoryError'>, 'InterruptedError': <class 'InterruptedError'>, 'PermissionError': <class 'PermissionError'>, 'ProcessLookupError': <class 'ProcessLookupError'>, 'TimeoutError': <class 'TimeoutError'>, 'open': <built-in function open>, 'copyright': Copyright (c) 2001-2023 Python Software Foundation.\n",
       " All Rights Reserved.\n",
       " \n",
       " Copyright (c) 2000 BeOpen.com.\n",
       " All Rights Reserved.\n",
       " \n",
       " Copyright (c) 1995-2001 Corporation for National Research Initiatives.\n",
       " All Rights Reserved.\n",
       " \n",
       " Copyright (c) 1991-1995 Stichting Mathematisch Centrum, Amsterdam.\n",
       " All Rights Reserved., 'credits':     Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n",
       "     for supporting Python development.  See www.python.org for more information., 'license': Type license() to see the full license text, 'help': Type help() for interactive help, or help(object) for help about object., 'execfile': <function execfile at 0x7ff4086fcb80>, 'runfile': <function runfile at 0x7ff408622680>, '__IPYTHON__': True, 'display': <function display at 0x7ff40b4bef80>, '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1017__': <capsule object NULL at 0x7ff3dd5b5dd0>, '__pybind11_internals_v4_gcc_libstdcpp_cxxabi1014__': <capsule object NULL at 0x7ff3cd7d9b60>, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7ff4083b1f60>>}}, locals={'i': 9})>)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [multiply, wiki, tavily, repl_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "eww24kgu_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7ff3ce426ad0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7ff3ce424940>, root_client=<openai.OpenAI object at 0x7ff3ce558b80>, root_async_client=<openai.AsyncOpenAI object at 0x7ff3ce426a70>, model_name='gpt-4o-mini', temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'), max_tokens=1024), kwargs={'tools': [{'type': 'function', 'function': {'name': 'multiply', 'description': 'x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.', 'parameters': {'properties': {'x': {'type': 'integer'}, 'y': {'type': 'integer'}}, 'required': ['x', 'y'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tavily_search_results_json', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'python_repl', 'description': 'A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWVSicuF_2iQ"
   },
   "source": [
    "이제 invoke를 통해 툴을 사용하도록 유도해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "zWO3ElzR_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_D55nWq7ZtoSMPchHBA2Znr7T', 'function': {'arguments': '{\"x\":32,\"y\":7}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 244, 'total_tokens': 262, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-61e7e73f-5f18-4277-b551-778d7e371bcc-0', tool_calls=[{'name': 'multiply', 'args': {'x': 32, 'y': 7}, 'id': 'call_D55nWq7ZtoSMPchHBA2Znr7T', 'type': 'tool_call'}], usage_metadata={'input_tokens': 244, 'output_tokens': 18, 'total_tokens': 262, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"32 * 7이 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "iqt0Yuva_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_m7YkAhX4syvD2ArqTdeNjgPB', 'function': {'arguments': '{\"query\":\"양자 컴퓨터\"}', 'name': 'wikipedia'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 246, 'total_tokens': 263, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f28e7dd7-2422-49a0-bbd7-06a3cc4a4ed0-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': '양자 컴퓨터'}, 'id': 'call_m7YkAhX4syvD2ArqTdeNjgPB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 246, 'output_tokens': 17, 'total_tokens': 263, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"양자 컴퓨터의 정의가 뭐야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSLWfy2y_2iQ"
   },
   "source": [
    "content 대신 tool_calls 가 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "q79PRxGj_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'x': 32, 'y': 7},\n",
       "  'id': 'call_UYpIkgGRUPyjSHqOdetsPkhg',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"32 * 7이 뭐야?\").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "yxW_7x11_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'wikipedia',\n",
       "  'args': {'query': '양자 컴퓨터'},\n",
       "  'id': 'call_DmU6HLbjCt9O2Ub6QXXwYPeL',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\"양자 컴퓨터의 정의가 뭐야?\").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "HrKvAJzx_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke(llm_with_tools.invoke(\"32 * 7이 뭐야?\").tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "lKwiKzkG_2iQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No good Wikipedia Search Result was found'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.invoke(llm_with_tools.invoke(\"양자 컴퓨터의 정의가 뭐야?\").tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No6-WbbhngUz"
   },
   "source": [
    "## LangChain Agent 만들기    \n",
    "\n",
    "위 Tool Calling의 결과를 바로 전달하여, 결과를 수행하는 에이전트를 만들어 보겠습니다.    \n",
    "\n",
    "RAG에서 사용했던 Retriever도 같이 활용하여, 강의자료와 웹 검색을 병행하는 에이전트를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "O8xMH4_8izzP"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "aclDWrqeirn-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39662\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "path_material = './papers/attention.pdf'\n",
    "\n",
    "# 비밀번호 포함된 PDF 열기\n",
    "try:\n",
    "    loader = PyPDFLoader(path_material,password=\"your password\")\n",
    "    pages = loader.load()\n",
    "except:\n",
    "    loader = PyPDFLoader(path_material)\n",
    "    pages = loader.load()\n",
    "\n",
    "\n",
    "# 하나의 코퍼스에 합치기\n",
    "\n",
    "corpus = Document(page_content='')\n",
    "for page in pages:\n",
    "    corpus.page_content+=(page.page_content) + '\\n---\\n'\n",
    "\n",
    "print(len(corpus.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "WYDpr4Se37dM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
    "# 0~1000, 900~1900, 1800~2700, ...\n",
    "\n",
    "chunks = text_splitter.split_documents([corpus])\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "QBCSHCzM3Org"
   },
   "outputs": [],
   "source": [
    "\n",
    "embeddings = OpenAIEmbeddings(model = 'text-embedding-3-large')\n",
    "\n",
    "Chroma().delete_collection()\n",
    "vector_store = Chroma.from_documents(chunks, embeddings)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxhvF7l9ngU0"
   },
   "source": [
    "`create_retriever_tool`을 이용해 Retriever를 툴로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "DgZdFPpzngU0"
   },
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "search_material = create_retriever_tool(retriever,\"LLM 교재 검색\",\n",
    "                                        \"LLM(거대 언어 모델) 교육의 강의자료를 검색합니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGVL5NJKngU0"
   },
   "source": [
    "Tavily API는 그대로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "Yc9W_xynngU0"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily = TavilySearchResults(max_results=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuyorirUngU0"
   },
   "source": [
    "Wikipedia 툴도 그대로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "vQcTjdpUngU0"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=1000)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mt_zAvUh_2iS"
   },
   "source": [
    "PythonREPL 툴도 그대로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "m7P-Zgaq_2iS"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python_repl = PythonREPL()\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
    "    func=python_repl.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdadOZtN_2iS"
   },
   "source": [
    "Multiply 툴도 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "qcfwNrNw_2iS"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(x:int, y:int) -> int:\n",
    "    \"x와 y를 입력받아, x와 y를 곱한 결과를 반환합니다.\"\n",
    "    return x*y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiB9XUb6_2iS"
   },
   "source": [
    "이번 실습에서는 Structured Chat Agent를 사용합니다.   \n",
    "ReAct(강의자료 참조) 의 원리에, json 형식의 출력을 활용한 방법입니다.   \n",
    "\n",
    "(https://python.langchain.com/v0.1/docs/modules/agents/agent_types/structured_chat/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "MGvzDWn7ngU0"
   },
   "outputs": [],
   "source": [
    "agent_prompt = ChatPromptTemplate.from_messages(messages=[\n",
    "                                  ('system','''\n",
    "최대한 정확히 질문에 답변하세요. 당신은 다음의 툴을 사용할 수 있습니다:\n",
    "{tools}\n",
    "\n",
    "action 키 (tool name)와 action_input 키를 포함하는 json 형태로 출력하세요.\n",
    "\n",
    "action의 값은 \"Final Answer\" 또는 {tool_names} 중 하나여야 합니다.\n",
    "반드시 하나의 json 형태만 출력하세요. 다음은 예시입니다.\n",
    "```\n",
    "{{\n",
    "\n",
    "  \"action\": $TOOL_NAME,\n",
    "\n",
    "  \"action_input\": $INPUT\n",
    "\n",
    "}}\n",
    "```\n",
    "\n",
    "아래의 포맷으로 답변하세요.:\n",
    "\n",
    "Question: 최종적으로 해결해야 하는 질문 혹은 지시사항\n",
    "Thought: 무엇을 해야 하는지를 항상 떠올리세요.\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: 액션의 실행 결과\n",
    "... (이 Thought/Action/Observation 은 !0번 이내로 반복될 수 있습니다.)\n",
    "\n",
    "Thought: 이제 답을 알겠다!\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human(Must be Korean)\"\n",
    "}}\n",
    "\n",
    "주어진 포맷을 잘 지켜야 하며, 한 번에 Thought와 Action을 동시에 쓰지 마세요.\n",
    "Question, Thought, Action, Observation의 출력 뒤에는 항상 줄을 바꾸세요.\n",
    "\n",
    "이제 입력이 주어집니다.json blob 형태로 출력해야 함을 명심하고,\n",
    "Thought의 경우에는 항상 Thought: 로 시작해야 합니다.\n",
    "포맷은 Action:```$JSON_BLOB``` 이후 Observation 입니다.\n",
    "'''),\n",
    "\n",
    "('user','''Question: {input}\n",
    "Thought: {agent_scratchpad}''')])\n",
    "# agent_scratchpad : 각 스텝의 결과를 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "UZa7ALt4ngU0"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_structured_chat_agent\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', max_tokens=1024, temperature=0.1)\n",
    "tools = [search_material, wiki, tavily, repl_tool, multiply]\n",
    "\n",
    "agent = create_structured_chat_agent(llm, tools, agent_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bc-DCspXB_O5"
   },
   "source": [
    "agent와 tool을 넣어 AgentExecutor를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "bcqWqhaOB_O5"
   },
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "P04EeTc7B_O5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: LLM 파인튜닝에 대한 정보를 찾아야 한다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"LLM 교재 검색\",\n",
      "  \"action_input\": {\n",
      "    \"query\": \"LLM 파인튜닝\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3mand 6. Note that the attentions are very sharp for this word.\n",
      "14\n",
      "---\n",
      "Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "\n",
      "of\n",
      "American\n",
      "governments\n",
      "have\n",
      "passed\n",
      "new\n",
      "laws\n",
      "since\n",
      "2009\n",
      "making\n",
      "the\n",
      "registration\n",
      "or\n",
      "voting\n",
      "process\n",
      "more\n",
      "difficult\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "<pad>\n",
      "Figure 3: An example of the attention mechanism following long-distance dependencies in the\n",
      "encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\n",
      "the verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\n",
      "the word ‘making’. Different colors represent different heads. Best viewed in color.\n",
      "13\n",
      "---\n",
      "Input-Input Layer5\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "\n",
      "On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\n",
      "outperforming all of the previously published single models, at less than 1/4 the training cost of the\n",
      "previous state-of-the-art model. The Transformer (big) model trained for English-to-French used\n",
      "dropout rate Pdrop = 0.1, instead of 0.3.\n",
      "For the base models, we used a single model obtained by averaging the last 5 checkpoints, which\n",
      "were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\n",
      "used beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\n",
      "\n",
      "[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\n",
      "corpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\n",
      "[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\n",
      "Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,\n",
      "pages 152–159. ACL, June 2006.\n",
      "[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\n",
      "model. In Empirical Methods in Natural Language Processing, 2016.\n",
      "[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\n",
      "\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
      "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
      "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\u001b[0m\u001b[32;1m\u001b[1;3mThought: LLM 파인튜닝에 대한 정보를 찾았으니, 이를 요약하여 답변을 준비해야 한다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"LLM 파인튜닝은 대규모 언어 모델(LLM)을 특정 작업이나 데이터셋에 맞게 조정하는 과정입니다. 이 과정은 모델이 특정 도메인이나 작업에 대해 더 나은 성능을 발휘하도록 하기 위해 기존의 모델을 추가적인 데이터로 학습시키는 것을 포함합니다. 파인튜닝을 통해 모델은 특정한 언어적 패턴이나 주제를 더 잘 이해하고 처리할 수 있게 됩니다.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'LLM 파인튜닝이 뭐야?',\n",
       " 'output': 'LLM 파인튜닝은 대규모 언어 모델(LLM)을 특정 작업이나 데이터셋에 맞게 조정하는 과정입니다. 이 과정은 모델이 특정 도메인이나 작업에 대해 더 나은 성능을 발휘하도록 하기 위해 기존의 모델을 추가적인 데이터로 학습시키는 것을 포함합니다. 파인튜닝을 통해 모델은 특정한 언어적 패턴이나 주제를 더 잘 이해하고 처리할 수 있게 됩니다.'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"LLM 파인튜닝이 뭐야?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "f7WeawXq_2iT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m레오나르도 디카프리오의 출생년도를 먼저 찾아야 합니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"wikipedia\",\n",
      "  \"action_input\": \"레오나르도 디카프리오\"\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\u001b[32;1m\u001b[1;3mThought: 위키피디아에서 레오나르도 디카프리오에 대한 정보를 찾지 못했으므로, 다른 방법으로 출생년도를 찾아야 합니다. 최신 정보를 얻기 위해 검색 엔진을 사용해 보겠습니다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": \"레오나르도 디카프리오 출생년도\"\n",
      "}\n",
      "```\n",
      "```\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'title': '레오나르도 디카프리오 - 나무위키', 'url': 'https://namu.wiki/w/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84%20%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4', 'content': '본명. Leonardo Wilhelm DiCaprio (레오나르도 빌헬름 디카프리오)[1] ; 출생. 1974년 11월 11일 (50세) ; 출생 · 캘리포니아 주 로스앤젤레스 할리우드.', 'score': 0.93086797}, {'title': '레오나르도 디카프리오 (r2003 판) - 나무위키', 'url': 'https://namu.wiki/w/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84%20%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4?uuid=37452b28-9a9b-409a-ab68-2b27a5cdab3d', 'content': '본명. Leonardo Wilhelm DiCaprio (레오나르도 빌헬름 디카프리오)[1] ; 출생. 1974년 11월 11일 (50세) ; 출생 · 미국 캘리포니아주 로스앤젤레스 할리우드.', 'score': 0.9281033}, {'title': '레오나르도 디카프리오 - 위키백과, 우리 모두의 백과사전', 'url': 'https://ko.wikipedia.org/wiki/%EB%A0%88%EC%98%A4%EB%82%98%EB%A5%B4%EB%8F%84_%EB%94%94%EC%B9%B4%ED%94%84%EB%A6%AC%EC%98%A4', 'content': '레오나르도 디카프리오 ; 1974년 11월 11일(1974-11-11)(50세) 미국 캘리포니아주 할리우드 · 미국 · 배우, 영화 제작자, 환경 운동가 · 1989년~현재.', 'score': 0.8967681}, {'title': 'Leonardo DiCaprio (레오나르도 디카프리오) - 네이버 블로그', 'url': 'https://m.blog.naver.com/jhyuna0812/221403708891', 'content': 'Leonardo DiCaprio. (레오나르도 디카프리오). 본명: Leonardo Wilhelm DiCaprio. 출생: 1974년 11월 11일, 미국. 직업: 배우.', 'score': 0.8896154}, {'title': '레오나르도 디카프리오(1/2) - 네이버 블로그', 'url': 'https://m.blog.naver.com/jaemoonlim/221773811410', 'content': '출생. 1974년 11월 11일 LA에서 태어났다. 어머니 이멀린 디카프리오 함께. 디카프리오 부모, 조지 와 이멀린 은 이탈리아 피렌체의 우피치 미술관에서.', 'score': 0.8875269}]\u001b[0m\u001b[32;1m\u001b[1;3m레오나르도 디카프리오의 출생년도는 1974년입니다. 이제 각 숫자를 순서대로 곱해보겠습니다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"multiply\",\n",
      "  \"action_input\": {\"x\": 1, \"y\": 9}\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3m9\u001b[0m\u001b[32;1m\u001b[1;3mThought: 첫 번째 숫자 1과 두 번째 숫자 9를 곱한 결과는 9입니다. 이제 세 번째 숫자 7과 곱해보겠습니다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"multiply\",\n",
      "  \"action_input\": {\"x\": 9, \"y\": 7}\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3m63\u001b[0m\u001b[32;1m\u001b[1;3mThought: 두 번째 숫자 9와 세 번째 숫자 7을 곱한 결과는 63입니다. 이제 마지막 숫자 4와 곱해보겠습니다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"multiply\",\n",
      "  \"action_input\": {\"x\": 63, \"y\": 4}\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3m252\u001b[0m\u001b[32;1m\u001b[1;3mThought: 이제 모든 숫자를 곱한 결과는 252입니다. 최종 결과를 정리하겠습니다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"레오나르도 디카프리오의 출생년도 1974의 각 숫자를 곱한 결과는 252입니다.\"\n",
      "} \n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '레오나르도 디카프리오의 출생년도를 찾은 뒤, 각 숫자를 순서대로 곱해줘.',\n",
       " 'output': '레오나르도 디카프리오의 출생년도 1974의 각 숫자를 곱한 결과는 252입니다.'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input':\"레오나르도 디카프리오의 출생년도를 찾은 뒤, 각 숫자를 순서대로 곱해줘.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "7iTawofTNg3J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 현재 2024년 11월의 chatbot arena에서 1위 모델에 대한 정보를 찾아야 한다. 최신 정보를 제공하는 검색 엔진을 사용해 보겠다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": \"2024년 11월 chatbot arena 1위 모델\"\n",
      "}\n",
      "```\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'title': 'OpenAI, 챗봇 아레나에서 1위를 되찾은 업데이트된 GPT-4o 모델 출시', 'url': 'https://coolenjoy.net/bbs/38/6231994', 'content': '순위에 따르면 ChatGPT-4o(20241120)는 지난주에 출시된 Gemini-Exp-1114 모델을 1361점으로 앞질렀습니다. 커뮤니티 점수에 따르면 최신 GPT-4o는 창의적', 'score': 0.914176}, {'title': 'Google의 새로운 Gemini 모델은 이제 모든 도메인에서 Chatbot Arena ...', 'url': 'https://coolenjoy.net/bbs/38/6271913', 'content': '인기 있는 Chatbot Arena 리더보드에서 ChatGPT-4o(20241120) 는 11월 21일에 1위 모델이 되었으며, 11월 15일에 출시된 Gemini-Exp-1114 모델을 앞지르게', 'score': 0.91362286}, {'title': '[11월의 AI 트렌드] AI 추론 속도가 여기서 더 빨라진다고?!', 'url': 'https://blog.skbroadband.com/416547', 'content': 'GPT-4o는 Chatbot Arena LLM 리더보드에서 1위를 차지했으며, 특히 창의적인 글쓰기, 코딩, 복잡한 명령어 처리에서 뛰어난 성능을 보였다. 무료', 'score': 0.72465646}, {'title': 'Grok-3, AI의 새 지평 열다\" – OpenAI·Google 모델을 뛰어넘은 이유와 ...', 'url': 'https://digitalbourgeois.tistory.com/787', 'content': '이후 2024년 3월 Grok-1.5, 8월 Grok-2 beta까지 6개월 간격으로 빠르게 모델 ... Grok-3는 Chatbot Arena에서 최초로 1400점을 돌파하며 1위를 차지', 'score': 0.6747586}, {'title': 'AI Network Arena 2주 간의 실험 결과: Gemini, 뜻밖의 승리 - Medium', 'url': 'https://medium.com/@ainetwork_korea/ai-network-arena-2%EC%A3%BC-%EA%B0%84%EC%9D%98-%EC%8B%A4%ED%97%98-%EA%B2%B0%EA%B3%BC-gemini-%EB%9C%BB%EB%B0%96%EC%9D%98-%EC%8A%B9%EB%A6%AC-951c046704cb', 'content': 'AI Network chatbot arena 리더보드에 따르면, 구글의 Gemini-1.5-pro-latest 모델은 1,354건의 win 투표를 받아 1위를 차지하였습니다. GPT 및 Claude 가', 'score': 0.614464}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: 검색 결과에 따르면, 2024년 11월 현재 Chatbot Arena에서 1위 모델은 ChatGPT-4o(20241120)이다. 이 모델은 최근에 출시된 Gemini-Exp-1114 모델을 제치고 1위를 차지했다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"2024년 11월 현재 Chatbot Arena에서 1위 모델은 ChatGPT-4o(20241120)입니다.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '2024년 11월 현재 chatbot arena 1위 모델이 뭐야?',\n",
       " 'output': '2024년 11월 현재 Chatbot Arena에서 1위 모델은 ChatGPT-4o(20241120)입니다.'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"2024년 11월 현재 chatbot arena 1위 모델이 뭐야?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "DjOvHU0UNNoN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search for the latest information regarding the best model in Chatbot Arena as of November 2024.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": \"best model in Chatbot Arena November 2024\"\n",
      "}\n",
      "```\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'title': \"Which organization's large language model (LLM) will be ranked ...\", 'url': 'https://www.gjopen.com/questions/3899-which-organization-s-large-language-model-llm-will-be-ranked-first-as-of-14-november-2025-according-to-chatbot-arena-formerly-lmsys-org', 'content': 'As of 5 December 2024, OpenAI was ranked first with its \"ChatGPT-4o-latest (2024-11-20)\" model with an Arena Score of 1366.', 'score': 0.818055}, {'title': \"Will OpenAI's o1 remain the top LLM in all categories of Chatbot ...\", 'url': 'https://www.metaculus.com/questions/29633/will-openais-o1-remain-the-top-llm-in-all-categories-of-chatbot-arena-on-november-30-2024/', 'content': \"Given that as of October 4, 2024, OpenAI's o1-preview model was ranked #1 in all categories of the Chatbot Arena, and there is no new\", 'score': 0.7309246}, {'title': 'Which Model is Best? To the LMSYS.org Chatbot Arena! - Medium', 'url': 'https://medium.com/@ericfrayer/which-model-is-best-to-the-lmsys-org-chatbot-arena-22dd62b3ecd5', 'content': \"With the recent announcements from Open AI, Google and Anthropic, I thought I should research LLM model performance and who's winning!\", 'score': 0.48879638}, {'title': 'Chatbot Arena Leaderboard - Manifold Markets', 'url': 'https://manifold.markets/topic/chatbot-arena-leaderboard', 'content': 'An AI model will rate higher than GPT-4-Turbo on the Chatbot Arena Leaderboard (OpenAI model or other) before May 2024.', 'score': 0.3794479}, {'title': 'The Best AI Chatbots & LLMs of Q1 2025: Rankings & Data - UpMarket', 'url': 'https://www.upmarket.co/blog/the-best-ai-chatbots-llms-of-q1-2025-complete-comparison-guide-and-research-firm-ranks/', 'content': '上市前独角兽股权 加密货币基金 另类私募基金 对冲基金 PE 私募基金 固定收益 房地产类基金 上市前独角兽股权 加密货币基金 另类私募基金 对冲基金 PE 私募基金 固定收益 房地产类基金 KeywordAvg. Search Volume(Last 3 months)chatgpt48,800,000gemini2,570,000deepseek2,070,000openai1,080,000perplexity941,000claude516,000perplexity ai323,000grok237,000nova216,000llama189,000anthropic167,000xai85,000kimi79,500tencent61,200yi60,500mistral49,500cohere35,500qwen17,000hunyuan6,600phi 45,100reka5,000lechat4,800ai21 labs1,100ernie bot750jurassic 2340lg ai research130 The team achieved breakthroughs in open-source AI models like DeepSeek-R1 through cost-effective optimization and pure reinforcement learning techniques, challenging established US competitors. Reka AI is a company specializing in developing cutting-edge multimodal artificial intelligence models, allowing users to interact with and understand information across various formats like text, images, and videos; their key focus is building generative AI models that can perform complex tasks like generating text based on images, understanding video content, and providing insightful analysis across different media types, with their primary product being a multimodal assistant called \"Yasa\" that can be customized for different enterprise applications.', 'score': 0.24499062}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I have found relevant information indicating that OpenAI's \"ChatGPT-4o-latest (2024-11-20)\" model was ranked first in the Chatbot Arena as of December 5, 2024. I need to confirm if this is the best model as of November 2024.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"2024년 11월 기준으로 Chatbot Arena에서 가장 좋은 모델은 OpenAI의 'ChatGPT-4o-latest (2024-11-20)'입니다.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the best model in Chatbot Arena in 2024 November?',\n",
       " 'output': \"2024년 11월 기준으로 Chatbot Arena에서 가장 좋은 모델은 OpenAI의 'ChatGPT-4o-latest (2024-11-20)'입니다.\"}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What is the best model in Chatbot Arena in 2024 November?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "hj5u6tyW_2iT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: 2024년 11월의 Chatbot Arena에서 가장 좋은 5개의 모델을 찾아야 합니다. 이를 위해 최신 정보를 검색해야 합니다. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"tavily_search_results_json\",\n",
      "  \"action_input\": \"best 5 models in Chatbot Arena November 2024\"\n",
      "}\n",
      "```\u001b[0m\u001b[38;5;200m\u001b[1;3m[{'title': 'The LLM Battleground: Which AI Model Reigns Supreme? | by Valere', 'url': 'https://valerelabs.medium.com/the-llm-battleground-which-ai-model-reigns-supreme-bbf44f39a7d0', 'content': 'But is it actually the best? · DeepSeek-R1 currently holds the highest Arena Elo rating of 1362 and an MMLU score of 90.8. · DeepSeek-V3 follows', 'score': 0.26329663}, {'title': 'Chatbot Arena Leaderboard - Manifold Markets', 'url': 'https://manifold.markets/topic/chatbot-arena-leaderboard', 'content': 'An AI model will rate higher than GPT-4-Turbo on the Chatbot Arena Leaderboard (OpenAI model or other) before May 2024.', 'score': 0.25995055}, {'title': 'The Best AI Chatbots & LLMs of Q1 2025: Rankings & Data - UpMarket', 'url': 'https://www.upmarket.co/blog/the-best-ai-chatbots-llms-of-q1-2025-complete-comparison-guide-and-research-firm-ranks/', 'content': '上市前独角兽股权 加密货币基金 另类私募基金 对冲基金 PE 私募基金 固定收益 房地产类基金 上市前独角兽股权 加密货币基金 另类私募基金 对冲基金 PE 私募基金 固定收益 房地产类基金 KeywordAvg. Search Volume(Last 3 months)chatgpt48,800,000gemini2,570,000deepseek2,070,000openai1,080,000perplexity941,000claude516,000perplexity ai323,000grok237,000nova216,000llama189,000anthropic167,000xai85,000kimi79,500tencent61,200yi60,500mistral49,500cohere35,500qwen17,000hunyuan6,600phi 45,100reka5,000lechat4,800ai21 labs1,100ernie bot750jurassic 2340lg ai research130 The team achieved breakthroughs in open-source AI models like DeepSeek-R1 through cost-effective optimization and pure reinforcement learning techniques, challenging established US competitors. Reka AI is a company specializing in developing cutting-edge multimodal artificial intelligence models, allowing users to interact with and understand information across various formats like text, images, and videos; their key focus is building generative AI models that can perform complex tasks like generating text based on images, understanding video content, and providing insightful analysis across different media types, with their primary product being a multimodal assistant called \"Yasa\" that can be customized for different enterprise applications.', 'score': 0.2503538}, {'title': 'Chatbot Arena - OpenLM.ai', 'url': 'https://openlm.ai/chatbot-arena/', 'content': '| Gemini-1.5-Flash-8B-001 | 1213 | 1208 |  |  | 37689 | Google | Proprietary | | Gemini-1.5-Flash-8B-Exp-0827 | 1205 | 1189 |  |  | 25344 | Google | Proprietary | | Reka-Flash-21B-online | 1156 | 1147 |  |  | 16023 | Reka AI | Proprietary | | Reka-Flash-21B | 1148 | 1141 |  | 73.5 | 25803 | Reka AI | Proprietary | | pplx-70B-online | 1078 | 1028 |  |  | 6890 | Perplexity AI | Proprietary | | Mistral-7B-Instruct-v0.2 | 1072 | 1074 | 12.57 |  | 20049 | Mistral | Apache-2.0 | | pplx-7B-online | 1044 | 1015 |  |  | 6338 | Perplexity AI | Proprietary | | OLMo-7B-instruct | 1016 | 1017 |  |  | 6501 | Allen AI | Apache-2.0 |', 'score': 0.21872815}, {'title': 'From GPT-4 to Llama 3: LMSYS Chatbot Arena Ranks Top LLMs', 'url': 'https://www.analyticsvidhya.com/blog/2024/05/from-gpt-4-to-llama-3-lmsys-chatbot-arena-ranks-top-llms/', 'content': 'The LMSYS Chatbot Arena evaluates, ranks and compares LLMs. Check out testing of top LLMs of 2025 on different parameters.', 'score': 0.21202022}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: 검색 결과에서 2024년 11월의 Chatbot Arena에서 가장 좋은 5개의 모델에 대한 정보를 찾아야 합니다. 각 모델의 이름을 정리하여 'models.txt' 파일에 저장할 수 있도록 준비하겠습니다.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"1. DeepSeek-R1\\n2. DeepSeek-V3\\n3. Gemini-1.5-Flash-8B-001\\n4. Reka-Flash-21B-online\\n5. Mistral-7B-Instruct-v0.2\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"save the best 5 models in Chatbot Arena in 2024 November as 'models.txt'\",\n",
       " 'output': '1. DeepSeek-R1\\n2. DeepSeek-V3\\n3. Gemini-1.5-Flash-8B-001\\n4. Reka-Flash-21B-online\\n5. Mistral-7B-Instruct-v0.2'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"save the best 5 models in Chatbot Arena in 2024 November as 'models.txt'\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KENPz11_2iT"
   },
   "source": [
    "LangChain Agent는 툴을 잘 사용하지만, 중간 개입이 어렵고    \n",
    "파싱 에러가 자주 발생한다는 단점이 있습니다.   \n",
    "(모델이 충분히 똑똑하지 못한 경우에는 더 불안정합니다.)\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TNj0WJ6ngVA"
   },
   "source": [
    "## LangGraph로 Agentic Application 만들기\n",
    "\n",
    "LangGraph를 사용하면, 훨씬 유연한 선택이 가능합니다.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czPC_0k3ngVB"
   },
   "source": [
    "Advanced RAG의 예시 중 하나인 Corrective RAG(CRAG)을 구현해 보겠습니다.\n",
    "\n",
    "CRAG은 Retrieval Evaluator를 이용하여, 검색된 Document를     \n",
    "`적합/부적합/불확실`로 분류하고, 웹 검색을 활용하여 이를 개선하는데요.\n",
    "\n",
    "\n",
    "이를 조금 단순화하여 적합/부적합의 형태로 분류하고,   \n",
    "Document 중 적합한 결과가 없으면 웹 서치를 수행하도록 작성해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TKtiykKngVB"
   },
   "source": [
    "![image](https://github.com/NotoriousH2/img_container/assets/4037207/dd334478-1284-44e1-bf4f-a40fa14ab986)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc8tgqN6Q9Xw"
   },
   "source": [
    "## 1. Retrieval Grader\n",
    "Retriever의 결과물을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "TS6jwblGngVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'attention이 기존의 lstm 기반의 모델보다 좋은 이유는?', 'document': 'sequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in', 'grade': 'attention 메커니즘이 LSTM 기반 모델보다 우수한 이유를 묻는 질문으로, 문서는 attention 메커니즘의 중요성과 그로 인해 얻는 이점에 대해 언급하고 있습니다. 따라서 문서는 질문에 대한 정보를 포함하고 있습니다. [결과]: Relevant', 'score': 'Yes'}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "\n",
    "\n",
    "# 'not relevant'가 있으면 'No'를 반환, 나머지 경우 'Yes' 반환\n",
    "def parse_relevance_score(response):\n",
    "    return 'No' if 'not relevant' in response['grade'].lower() else 'Yes'\n",
    "\n",
    "\n",
    "structured_llm_grader = llm\n",
    "\n",
    "# 평가 프롬프트\n",
    "system = \"\"\"당신은 주어진 [질문]과 검색된 [문서] 사이의 연관성을 판단해야 합니다.\n",
    "[질문]을 답변하기 위한 정보를 [문서]가 포함하고 있는지를 설명하세요.\n",
    "그 이후, [결과]에 'Relevant' 또는 'Not Relevant'를 출력하세요.\n",
    "다음은 예시 답변입니다.\n",
    "\n",
    "예시)\n",
    "[답변]: 이 질문은 공룡의 멸종 원인을 묻는 질문으로, 문서는 공룡과 관련이 없는 내용입니다. [결과]: Not Relevant\n",
    "\n",
    "[답변]: 이 질문은 프롬프트 엔지니어링의 장점을 묻는 질문인데, 문서는 프롬프트 엔지니어링에 대해 다루고 있습니다. [결과]: Relevant\n",
    "\n",
    "[답변]: 이 질문은 지구 온난화의 주요 원인을 묻는 질문으로, 문서는 중세 시대의 역사적 사건들에 대해 다루고 있습니다. [결과]: Not Relevant\n",
    "\n",
    "[답변]: 이 질문은 로마 제국의 멸망 원인을 묻는 질문으로, 문서는 로마 제국의 경제 구조와 사회적 변화에 대해 다루고 있습니다. [결과]: Relevant\n",
    "\n",
    "[답변]: 이 질문은 현대 인공지능의 윤리적 문제를 묻는 질문으로, 문서는 최신 영화 리뷰와 평점에 대해 다루고 있습니다. [결과]: Not Relevant\n",
    "\n",
    "시작\n",
    "\n",
    "[답변]:\"\"\"\n",
    "\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"[문서]: \\n\\n {document} \\n\\n [질문]: {question} [답변]: 이 질문은 \\n\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# question, doc, grade, score 순서로 출력하기\n",
    "\n",
    "retrieval_grader = RunnableParallel(\n",
    "    question = lambda x:x['question'],\n",
    "    document = lambda x:x['document'],\n",
    "    ).assign(grade = grade_prompt | structured_llm_grader | StrOutputParser()\n",
    "    ).assign(score=parse_relevance_score)\n",
    "\n",
    "def retrieval_test(question):\n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    doc_txt = docs[1].page_content\n",
    "\n",
    "    print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))\n",
    "\n",
    "question1 = \"강아지와 고양이 중 뇌세포 수가 누가 더 많은가요?\"\n",
    "\n",
    "question2 = \"attention이 기존의 lstm 기반의 모델보다 좋은 이유는?\"\n",
    "\n",
    "retrieval_test(question2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZfmQCCETSPo"
   },
   "source": [
    "## 2. RAG-Chain\n",
    "\n",
    "Context와 Question을 바탕으로 질문에 답변합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "oVgB7xXJngVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention은 쿼리와 키-값 쌍을 매핑하여 출력을 생성하는 메커니즘으로, 쿼리와 해당 키의 호환성 함수에 따라 값에 가중치를 부여하여 출력의 가중합을 계산합니다. Self-Attention은 동일한 시퀀스 내의 서로 다른 위치를 연결하여 시퀀스의 표현을 계산하는 주의 메커니즘입니다. 이 메커니즘은 독해, 요약 등 다양한 작업에서 성공적으로 사용되며, 특히 긴 거리 의존성을 학습하는 데 유용합니다. Self-Attention은 인코더와 디코더 모두에서 사용되며, 각 위치가 이전 레이어의 모든 위치에 주의를 기울일 수 있도록 합니다.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", '''당신은 QA(Question-Answering)을 수행하는 Assistant입니다. 다음의 Context를 이용하여 Question에 답변하세요.\n",
    "최소 3문장에서 최대 5문장으로 답변하고, 정확한 답변을 제공하세요.\n",
    "만약 모든 Context를 다 확인해도 정보가 없다면, \"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.\n",
    "답변은 한국어로 작성하세요.\n",
    "---\n",
    "Context: {context}\n",
    "---\n",
    "Question: {question}''')])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n---\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Context, Question은 다른 체인에서 전달되므로, prompt부터 구성\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "question = \"Attention과 Self-Attention에 대해 설명?\" # 컹컹 크르르르 크앙 컹컹컹 # 사람과 개의 뇌세포 수는 어떻게 다른가?\n",
    "docs = retriever.invoke(question)\n",
    "\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN4n4aKoTrvc"
   },
   "source": [
    "## 3. Question Rewriter\n",
    "\n",
    "질문을 재구성하여 다시 검색할 수 있는 쿼리를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "GGFLaE8fngVB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attention과 Self-Attention의 개념에 대해 자세히 설명해 주실 수 있나요?'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system = \"\"\"당신은 주어진 질문을 재작성해야 합니다. 질문의 의미가 더 명확하게 드러나도록 Rewrite 하세요.\n",
    "영어를 한국어로 번역하지 마세요.\"\"\"\n",
    "\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"user\", \"원본 질문: {question} \\n 새로운 질문:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Br9bcMDPngVC"
   },
   "source": [
    "Retrieval-Grader, RAG, Question Re-writer는 각각 LangChain으로 구성된 체인입니다.    \n",
    "이를 이용하여 LangGraph Agent를 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keKY7NBjngVC"
   },
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XU55UJVQngVC"
   },
   "source": [
    "langgraph에서는 `GraphState`의 형태로 Agent의 활동 상태를 정의합니다.   \n",
    "에이전트는 여러 개의 노드를 오가며 State에 상태값을 저장하고, 이를 체인에 전달하여 결과를 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUXbqSRungVC"
   },
   "source": [
    "\n",
    "![image](https://github.com/NotoriousH2/img_container/assets/4037207/781ae921-426a-410b-888d-04e965e14794)\n",
    "\n",
    "\n",
    "Source: https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_crag.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rpfsK9BU0Bi"
   },
   "source": [
    "어플리케이션의 과정에서 값을 저장할 클래스 `CRAGState`를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "KqGhZ2BOngVC"
   },
   "outputs": [],
   "source": [
    "# typing : 변수 타입을 명시해줄 수 있음\n",
    "# TypeDict : Dict의 원소 명시\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class CRAGState(TypedDict):\n",
    "\n",
    "    question: str\n",
    "    # 질문\n",
    "    generation: str\n",
    "    # 생성 결과\n",
    "    needed_web_search: bool\n",
    "    # 웹 서치가 필요한지 판단\n",
    "\n",
    "    documents: List[str]\n",
    "    # Retrieval+ Web Search 결과 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gv7X-j64V3eq"
   },
   "source": [
    "LangGraph에서 각각의 기능들은 함수로 정의되는데, 이를 노드나 엣지로 표현합니다.    \n",
    "\n",
    "함수가 실행되는 경우, 위에서 구성한 `CRAGState`를 받아 해당 내용을 계속 수정하며 진행하게 됩니다.   \n",
    "함수의 Return은 Dict로 전달되는데, 이는 State의 값으로 업데이트됩니다.   \n",
    "위에서 만든 Chain을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "26yTmWCYngVC"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "# 질문이 들어오면 Retriever 실행\n",
    "def retrieve(state):\n",
    "    print(\"---검색---\")\n",
    "    question = state[\"question\"] # 질문\n",
    "\n",
    "    # Retrieval 실행\n",
    "    documents = retriever.invoke(question)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "    # State에 documents, question 전달\n",
    "\n",
    "\n",
    "# Question + Documents 받아서 RAG 실행\n",
    "def generate(state):\n",
    "\n",
    "    print(\"---생성---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    print(\"**************DOCUMENTS****************\")\n",
    "    print('\\n---\\n'.join([doc.page_content for doc in documents]))\n",
    "    print(\"***************************************\")\n",
    "\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "    # State에 generation 추가 (나머지는 주어진 값)\n",
    "\n",
    "\n",
    "# Documents 연관성 평가\n",
    "def grade_documents(state):\n",
    "\n",
    "    print(\"---쿼리 연관성 검색---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # 분류 결과가 Relevant인 문서만 저장하기\n",
    "    filtered_docs = []\n",
    "\n",
    "    # True에서 바뀌지 않으면 웹 서치 실행하는 단계로 이동\n",
    "    needed_web_search = True\n",
    "\n",
    "\n",
    "    for doc in documents:\n",
    "\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": doc.page_content}\n",
    "        )['score']\n",
    "\n",
    "\n",
    "        if score=='No':\n",
    "            print(\"---GRADE: 관련성 없음---\")\n",
    "\n",
    "        else:\n",
    "            print(\"---GRADE: 관련성 확인---\")\n",
    "            filtered_docs.append(doc)\n",
    "            needed_web_search =  False\n",
    "\n",
    "\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"needed_web_search\": needed_web_search}\n",
    "    # 관련있는 문서만 추출하여 documents에 업데이트하고, 웹 서치가 필요한지 전달\n",
    "\n",
    "\n",
    "# 질문 Rewriting 체인 실행\n",
    "def transform_query(state):\n",
    "\n",
    "    print(\"---쿼리 재조합---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "\n",
    "    print('BEFORE:', question)\n",
    "    print('AFTER:', better_question)\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "# Tavily로 웹 서치 실행\n",
    "def web_search(state):\n",
    "\n",
    "    print(\"---WEB SEARCH---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 빈 문서에서 시작하는 이유?\n",
    "    documents = []\n",
    "\n",
    "    get_query_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"주어진 [질문]에 대한 정보를 얻기 위해, 웹 검색을 하고 싶습니다. [질문]을 적절한 영문 쿼리로 변환하세요.\n",
    "쿼리는 주로 단어들의 집합으로 나타내집니다.\"\"\"),\n",
    "        ('user','[질문]: {question}')\n",
    "\n",
    "    ])\n",
    "\n",
    "    # 쿼리 생성 체인\n",
    "    query_chain = get_query_prompt | llm | StrOutputParser()\n",
    "\n",
    "    # 새로운 쿼리 생성\n",
    "    new_query = query_chain.invoke({\"question\": question})\n",
    "\n",
    "\n",
    "    # 새 쿼리로 Web search\n",
    "    docs = tavily.invoke(new_query)\n",
    "\n",
    "    try:\n",
    "        web_results = \"\\n--------\\n\".join([doc[\"content\"] for doc in docs])\n",
    "\n",
    "    except Exception as e: # 400 Error (한국어 검색어인 경우 가끔 나타남)\n",
    "        print(new_query,e)\n",
    "        web_results=''\n",
    "\n",
    "    web_results = Document(page_content=web_results)\n",
    "\n",
    "\n",
    "    print(f\"\"\"---Query Generation---\n",
    "Before: {question}\n",
    "After: {new_query}\n",
    "\"\"\")\n",
    "\n",
    "    print(web_results)\n",
    "\n",
    "    # 검색결과 저장\n",
    "    documents.append(web_results)\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCt29f5HYgs-"
   },
   "source": [
    "위 함수들은 그래프의 노드(동그라미) 역할을 했다면,    \n",
    "엣지(마름모) 역할을 하는 함수는 조건 분기의 역할을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "hTTVLOq4YgBh"
   },
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "\n",
    "    print(\"---평가 결과를 확인합니다---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    needed_web_search = state[\"needed_web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if needed_web_search :# 웹 검색이 필요하면 transform_query 상태로 이동\n",
    "        print(\n",
    "            \"---DECISION: 지금 Context로 답변 불가---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "\n",
    "\n",
    "    else: # 필요하지 않으면 generate로 이동\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PY8_-fuGZYy7"
   },
   "source": [
    "모든 구성 요소를 그래프로 연결합니다.    \n",
    "노드의 이름과 함수를 결합해 노드를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "ylRSKHfnngVD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7ff3c8819ba0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "\n",
    "workflow = StateGraph(CRAGState)\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search_node\", web_search)\n",
    "\n",
    "# 시작점 : Retrieve\n",
    "workflow.set_entry_point(\"retrieve\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTsQVLYtZzH3"
   },
   "source": [
    "노드들을 연결하는 엣지를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "RnsWgF7XZ20d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7ff3c8819ba0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검색 후 결과 평가\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "# 결과 평가의 결과에 따라 둘 중 하나로 이동하는 분기 엣지\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# 쿼리 재생성 후 웹 서치\n",
    "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
    "\n",
    "# 웹 서치 후 생성\n",
    "workflow.add_edge(\"web_search_node\", \"generate\")\n",
    "\n",
    "# 생성하고 나면 에이전트 종료\n",
    "workflow.add_edge(\"generate\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JlTGzxGaExQ"
   },
   "source": [
    "구성된 그래프를 컴파일하여 최종적인 Agentic Workflow를 완성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "vsis9SScaD6g"
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "orJ2fyDUPr9B"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7ff3c8819810>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "9s5SNOnNp8MY"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0hRTw-iaNEB"
   },
   "source": [
    "## LangGraph Agent 실행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oi6lCM-fbSZH"
   },
   "source": [
    "question을 전달하여 에이전트를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "f-cy-txSngVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---검색---\n",
      "\"Node 'retrieve':\"\n",
      "'---'\n",
      "---쿼리 연관성 검색---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 없음---\n",
      "---평가 결과를 확인합니다---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'---'\n",
      "---생성---\n",
      "**************DOCUMENTS****************\n",
      "it more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\n",
      "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
      "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
      "described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
      "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
      "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
      "---\n",
      "around each of the sub-layers, followed by layer normalization. We also modify the self-attention\n",
      "sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\n",
      "masking, combined with fact that the output embeddings are offset by one position, ensures that the\n",
      "predictions for position i can depend only on the known outputs at positions less than i.\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "---\n",
      "Scaled Dot-Product Attention\n",
      " Multi-Head Attention\n",
      "---\n",
      "position in the decoder to attend over all positions in the input sequence. This mimics the\n",
      "typical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n",
      "[38, 2, 9].\n",
      "• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\n",
      "and queries come from the same place, in this case, the output of the previous layer in the\n",
      "encoder. Each position in the encoder can attend to all positions in the previous layer of the\n",
      "encoder.\n",
      "• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\n",
      "all positions in the decoder up to and including that position. We need to prevent leftward\n",
      "***************************************\n",
      "\"Node 'generate':\"\n",
      "'---'\n",
      "Attention은 쿼리와 키-값 쌍을 매핑하여 출력을 생성하는 함수로, 쿼리, 키, 값, 출력 모두 벡터로 표현됩니다. 이 과정에서 출력은 가중합으로 계산됩니다. Self-attention은 특정 시퀀스 내의 서로 다른 위치들 간의 관계를 파악하여 시퀀스의 표현을 계산하는 메커니즘으로, 주로 읽기 이해나 요약과 같은 다양한 작업에 성공적으로 사용됩니다. Self-attention은 인코더와 디코더 모두에서 사용되며, 인코더에서는 이전 레이어의 모든 위치에 접근할 수 있고, 디코더에서는 현재 위치까지의 모든 위치에 접근할 수 있도록 설계됩니다.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\"question\": \"Attention과 Self-Attetion은 무엇인가요?\"}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "    pprint(\"---\")\n",
    "\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "yzibT4BMngVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---검색---\n",
      "\"Node 'retrieve':\"\n",
      "'---'\n",
      "---쿼리 연관성 검색---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 없음---\n",
      "---GRADE: 관련성 없음---\n",
      "---평가 결과를 확인합니다---\n",
      "---DECISION: 지금 Context로 답변 불가---\n",
      "\"Node 'grade_documents':\"\n",
      "'---'\n",
      "---쿼리 재조합---\n",
      "BEFORE: Who is Sam Altman?\n",
      "AFTER: Sam Altman은 누구인가요?\n",
      "\"Node 'transform_query':\"\n",
      "'---'\n",
      "---WEB SEARCH---\n",
      "---Query Generation---\n",
      "Before: Sam Altman은 누구인가요?\n",
      "After: Query: \"Who is Sam Altman?\"\n",
      "\n",
      "page_content='Sam Altman, the CEO of OpenAI. Before leading OpenAI, Sam Altman was the president of Y Combinator, a startup accelerator that has launched companies including Airbnb, Instacart, and Dropbox. Now Altman is leading one of the hottest and most important companies of the moment: OpenAI, which has launched ChatGPT and, most recently, the AI video generator Sora. During OpenAI’s early years, Altman remained Y Combinator’s president and stayed involved from a distance. Altman raised the first billion-dollar investment from Microsoft, which would provide the Azure cloud service for OpenAI’s large AI models to scale. Altman replaced the title of OpenAI’s AI chatbot, “Chat with GPT-3.5,” with the slightly pithier ChatGPT. French President Emmanuel Macron, left, meets with OpenAI CEO Sam Altman.\n",
      "--------\n",
      "Michael Calore: Sam Altman is the CEO and one of the founders of OpenAI, the generative AI company that launched ChatGPT about two years ago, and essentially ushered in a new era of artificial intelligence. Michael Calore: I think it's important to also make the distinction that there were a lot of companies working on artificial intelligence at this time, about eight or nine years ago, and OpenAI saw themselves as the good guys in the group. Now, there are things that the company is doing that I think are very good, like the idea of a productivity tool or a suite of productivity tools that can help people do their jobs better.\n",
      "--------\n",
      "Who is Sam Altman, the man behind the AI revolution? ... Chicago-born Sam Altman joined Stanford University in 2004 to study computer science, but\n",
      "--------\n",
      "Altman’s contributions to the tech industry, his work in AI ethics, and his vision for the future of AI have left an indelible mark on the world. Sam Altman’s journey from a small town to a leading role in AI research and tech entrepreneurship serves as an inspiration to many, highlighting the possibilities for success through innovation, perseverance, and a commitment to ethical technology development. The overarching lesson from Sam Altman’s life and career is the importance of pursuing one’s passions, adapting to new challenges, and using technology and entrepreneurship to make a positive impact on society. In addition to his work in technology and AI, Sam Altman has been involved in biotechnology, longevity research, and universal basic income (UBI).\n",
      "--------\n",
      "Following the acquisition of Loopt, Altman joined Y Combinator (YC), a prestigious startup accelerator known for nurturing early-stage startups. OpenAI’s mission resonated deeply with Altman, who has long been an advocate for the ethical development and deployment of AI technologies. Under Altman’s leadership, OpenAI has made significant strides in advancing AI research. In a dramatic turn of events in 2023, Sam Altman was unexpectedly fired from his position as CEO of OpenAI, causing a stir within the tech community. As the world continues to grapple with the implications of rapid technological advancement, Altman’s leadership and foresight will undoubtedly play a crucial role in shaping a future that benefits all of humanity. LINKEDIN: https://www.linkedin.com/company/business-over-drinks This offer is available to Business over Drinks listeners, so click on the link above and get started.'\n",
      "\"Node 'web_search_node':\"\n",
      "'---'\n",
      "---생성---\n",
      "**************DOCUMENTS****************\n",
      "Sam Altman, the CEO of OpenAI. Before leading OpenAI, Sam Altman was the president of Y Combinator, a startup accelerator that has launched companies including Airbnb, Instacart, and Dropbox. Now Altman is leading one of the hottest and most important companies of the moment: OpenAI, which has launched ChatGPT and, most recently, the AI video generator Sora. During OpenAI’s early years, Altman remained Y Combinator’s president and stayed involved from a distance. Altman raised the first billion-dollar investment from Microsoft, which would provide the Azure cloud service for OpenAI’s large AI models to scale. Altman replaced the title of OpenAI’s AI chatbot, “Chat with GPT-3.5,” with the slightly pithier ChatGPT. French President Emmanuel Macron, left, meets with OpenAI CEO Sam Altman.\n",
      "--------\n",
      "Michael Calore: Sam Altman is the CEO and one of the founders of OpenAI, the generative AI company that launched ChatGPT about two years ago, and essentially ushered in a new era of artificial intelligence. Michael Calore: I think it's important to also make the distinction that there were a lot of companies working on artificial intelligence at this time, about eight or nine years ago, and OpenAI saw themselves as the good guys in the group. Now, there are things that the company is doing that I think are very good, like the idea of a productivity tool or a suite of productivity tools that can help people do their jobs better.\n",
      "--------\n",
      "Who is Sam Altman, the man behind the AI revolution? ... Chicago-born Sam Altman joined Stanford University in 2004 to study computer science, but\n",
      "--------\n",
      "Altman’s contributions to the tech industry, his work in AI ethics, and his vision for the future of AI have left an indelible mark on the world. Sam Altman’s journey from a small town to a leading role in AI research and tech entrepreneurship serves as an inspiration to many, highlighting the possibilities for success through innovation, perseverance, and a commitment to ethical technology development. The overarching lesson from Sam Altman’s life and career is the importance of pursuing one’s passions, adapting to new challenges, and using technology and entrepreneurship to make a positive impact on society. In addition to his work in technology and AI, Sam Altman has been involved in biotechnology, longevity research, and universal basic income (UBI).\n",
      "--------\n",
      "Following the acquisition of Loopt, Altman joined Y Combinator (YC), a prestigious startup accelerator known for nurturing early-stage startups. OpenAI’s mission resonated deeply with Altman, who has long been an advocate for the ethical development and deployment of AI technologies. Under Altman’s leadership, OpenAI has made significant strides in advancing AI research. In a dramatic turn of events in 2023, Sam Altman was unexpectedly fired from his position as CEO of OpenAI, causing a stir within the tech community. As the world continues to grapple with the implications of rapid technological advancement, Altman’s leadership and foresight will undoubtedly play a crucial role in shaping a future that benefits all of humanity. LINKEDIN: https://www.linkedin.com/company/business-over-drinks This offer is available to Business over Drinks listeners, so click on the link above and get started.\n",
      "***************************************\n",
      "\"Node 'generate':\"\n",
      "'---'\n",
      "샘 알트만(Sam Altman)은 OpenAI의 CEO이자 공동 창립자로, 인공지능(AI) 분야에서 중요한 역할을 하고 있는 인물입니다. 그는 Y Combinator의 사장을 역임하며 여러 스타트업을 지원했으며, OpenAI의 윤리적 AI 개발에 대한 강력한 지지자로 알려져 있습니다. 알트만은 OpenAI의 ChatGPT와 같은 혁신적인 AI 제품을 출시하며 AI 연구를 발전시키는 데 기여했습니다. 그러나 2023년에는 OpenAI의 CEO로서 예기치 않게 해임되는 사건이 발생하여 기술 커뮤니티에 큰 파장을 일으켰습니다. 그의 경력은 기술과 기업가정신을 통해 사회에 긍정적인 영향을 미치는 가능성을 보여주는 영감을 주는 사례로 평가받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"Who is Sam Altman?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "    pprint(\"---\")\n",
    "\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "-ed_X1rsngVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---검색---\n",
      "\"Node 'retrieve':\"\n",
      "'---'\n",
      "---쿼리 연관성 검색---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 없음---\n",
      "---평가 결과를 확인합니다---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'---'\n",
      "---생성---\n",
      "**************DOCUMENTS****************\n",
      "layers, produce outputs of dimension dmodel = 512 .\n",
      "Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\n",
      "sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\n",
      "attention over the output of the encoder stack. Similar to the encoder, we employ residual connections\n",
      "around each of the sub-layers, followed by layer normalization. We also modify the self-attention\n",
      "sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\n",
      "masking, combined with fact that the output embeddings are offset by one position, ensures that the\n",
      "predictions for position ican depend only on the known outputs at positions less than i.\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "---\n",
      "Scaled Dot-Product Attention\n",
      "---\n",
      "2\n",
      "---\n",
      "Figure 1: The Transformer - model architecture.\n",
      "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
      "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
      "respectively.\n",
      "3.1 Encoder and Decoder Stacks\n",
      "Encoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\n",
      "sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\n",
      "wise fully connected feed-forward network. We employ a residual connection [ 11] around each of\n",
      "the two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\n",
      "LayerNorm( x+ Sublayer( x)), where Sublayer( x)is the function implemented by the sub-layer\n",
      "itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\n",
      "layers, produce outputs of dimension dmodel = 512 .\n",
      "---\n",
      "position in the decoder to attend over all positions in the input sequence. This mimics the\n",
      "typical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n",
      "[38, 2, 9].\n",
      "•The encoder contains self-attention layers. In a self-attention layer all of the keys, values\n",
      "and queries come from the same place, in this case, the output of the previous layer in the\n",
      "encoder. Each position in the encoder can attend to all positions in the previous layer of the\n",
      "encoder.\n",
      "•Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\n",
      "all positions in the decoder up to and including that position. We need to prevent leftward\n",
      "information flow in the decoder to preserve the auto-regressive property. We implement this\n",
      "inside of scaled dot-product attention by masking out (setting to −∞) all values in the input\n",
      "of the softmax which correspond to illegal connections. See Figure 2.\n",
      "3.3 Position-wise Feed-Forward Networks\n",
      "---\n",
      "language modeling tasks [34].\n",
      "To the best of our knowledge, however, the Transformer is the first transduction model relying\n",
      "entirely on self-attention to compute representations of its input and output without using sequence-\n",
      "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
      "self-attention and discuss its advantages over models such as [17, 18] and [9].\n",
      "3 Model Architecture\n",
      "Most competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35].\n",
      "Here, the encoder maps an input sequence of symbol representations (x1, ..., x n)to a sequence\n",
      "of continuous representations z= (z1, ..., z n). Given z, the decoder then generates an output\n",
      "sequence (y1, ..., y m)of symbols one element at a time. At each step the model is auto-regressive\n",
      "[10], consuming the previously generated symbols as additional input when generating the next.\n",
      "2\n",
      "---\n",
      "Figure 1: The Transformer - model architecture.\n",
      "***************************************\n",
      "\"Node 'generate':\"\n",
      "'---'\n",
      "디코더(Decoder)는 Transformer 모델의 구성 요소 중 하나로, 입력 시퀀스의 정보를 바탕으로 출력 시퀀스를 생성하는 역할을 합니다. 디코더는 N=6개의 동일한 레이어로 구성되어 있으며, 각 레이어는 두 개의 서브 레이어와 추가적인 서브 레이어를 포함합니다. 이 추가 서브 레이어는 인코더 스택의 출력에 대해 다중 헤드 주의(attention)를 수행하여, 이전에 생성된 출력에 기반하여 다음 출력을 예측할 수 있도록 합니다. 디코더는 자기 주의(self-attention) 메커니즘을 사용하여 현재 위치까지의 정보를 활용하며, 이후의 위치에 대한 정보는 차단하여 오토 회귀(auto-regressive) 특성을 유지합니다.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"Decorder가 뭐야?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "\n",
    "        pprint(f\"Node '{key}':\")\n",
    "    pprint(\"---\")\n",
    "\n",
    "\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "pQdVS1SHp8MY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---검색---\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---쿼리 연관성 검색---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---GRADE: 관련성 확인---\n",
      "---평가 결과를 확인합니다---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---생성---\n",
      "**************DOCUMENTS****************\n",
      "language modeling tasks [34].\n",
      "To the best of our knowledge, however, the Transformer is the first transduction model relying\n",
      "entirely on self-attention to compute representations of its input and output without using sequence-\n",
      "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
      "self-attention and discuss its advantages over models such as [17, 18] and [9].\n",
      "3 Model Architecture\n",
      "Most competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35].\n",
      "Here, the encoder maps an input sequence of symbol representations (x1, ..., x n)to a sequence\n",
      "of continuous representations z= (z1, ..., z n). Given z, the decoder then generates an output\n",
      "sequence (y1, ..., y m)of symbols one element at a time. At each step the model is auto-regressive\n",
      "[10], consuming the previously generated symbols as additional input when generating the next.\n",
      "2\n",
      "---\n",
      "Figure 1: The Transformer - model architecture.\n",
      "---\n",
      "2\n",
      "---\n",
      "Figure 1: The Transformer - model architecture.\n",
      "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
      "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
      "respectively.\n",
      "3.1 Encoder and Decoder Stacks\n",
      "Encoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\n",
      "sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\n",
      "wise fully connected feed-forward network. We employ a residual connection [ 11] around each of\n",
      "the two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\n",
      "LayerNorm( x+ Sublayer( x)), where Sublayer( x)is the function implemented by the sub-layer\n",
      "itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\n",
      "layers, produce outputs of dimension dmodel = 512 .\n",
      "---\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
      "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
      "2 Background\n",
      "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n",
      "[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\n",
      "block, computing hidden representations in parallel for all input and output positions. In these models,\n",
      "the number of operations required to relate signals from two arbitrary input or output positions grows\n",
      "in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\n",
      "it more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\n",
      "---\n",
      "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "significant improvements in computational efficiency through factorization tricks [ 21] and conditional\n",
      "computation [ 32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "---\n",
      "Parser [29] even when training only on the WSJ training set of 40K sentences.\n",
      "7 Conclusion\n",
      "In this work, we presented the Transformer, the first sequence transduction model based entirely on\n",
      "attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\n",
      "multi-headed self-attention.\n",
      "For translation tasks, the Transformer can be trained significantly faster than architectures based\n",
      "on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\n",
      "English-to-French translation tasks, we achieve a new state of the art. In the former task our best\n",
      "model outperforms even all previously reported ensembles.\n",
      "We are excited about the future of attention-based models and plan to apply them to other tasks. We\n",
      "plan to extend the Transformer to problems involving input and output modalities other than text and\n",
      "to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\n",
      "***************************************\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "Transformer 모델은 전통적인 순환 신경망(RNN)이나 합성곱 신경망(CNN)을 사용하지 않고, 완전히 자기 주의(attention) 메커니즘에 의존하여 입력과 출력 간의 전역 의존성을 모델링하는 것이 특징입니다. 이 구조는 인코더-디코더 형태로 구성되어 있으며, 인코더는 입력 시퀀스를 연속 표현으로 변환하고, 디코더는 이를 바탕으로 출력 시퀀스를 생성합니다. 또한, Transformer는 병렬 처리를 가능하게 하여 훈련 속도를 크게 향상시키며, 번역 품질에서도 새로운 최첨단 성능을 달성할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"question\": \"Transformer 모델의 특징이 뭐야?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "\n",
    "        pprint(f\"Node '{key}':\")\n",
    "    pprint(\"\\n---\\n\")\n",
    "\n",
    "print(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfZR7UJH_2iW"
   },
   "source": [
    "# 실습) Corrective RAG Scheme 수정하기   \n",
    "\n",
    "검색 결과 중 irrelevant한 정보가 존재하면, 웹 검색을 통해 이를 보충하도록 flow를 수정해 보세요.   \n",
    "**Hint**: 웹 검색을 수행하는 조건을 변경하고, 웹 검색을 할 때 기존 문서값을 가져오도록 만들어 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzWGocdQ_2iW"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
